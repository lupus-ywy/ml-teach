{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 第一部分",
   "id": "c216d8cee0365df1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 简答题",
   "id": "c63b52b914e7bb74"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. 为什么激活函数是训练一个多层感知机（MLP）的关键要素\n",
    "\n",
    "没有激活函数，多层神经网络无法学习非线性关系，激活函数可以逼近任意复杂的函数\n",
    "\n",
    "2. 列举三种常用的激活函数，说明一下它们的大概形状\n",
    "\n",
    "ReLU\n",
    "x<0的时候为0，x>0的时候为x\n",
    "\n",
    "Sigmoid\n",
    "S型曲线，在0附近陡峭，两端趋于平缓\n",
    "\n",
    "tanh\n",
    "S型曲线，范围在-1到1\n",
    "\n",
    "3. 反向传播的算法解决什么问题，如何工作的\n",
    "\n",
    "解决多层网络的梯度问题\n",
    "先前向传播，计算每一层的激活值\n",
    "在反向传播，根据前向传播保存的激活值和链式法则来计算每一层的梯度\n",
    "然后更新参数\n",
    "\n",
    "4. 列出可以在基本MLP（不考虑其他神经网络架构）中进行调整的所有超参数？如果MLP过拟合训练数据，如何调整这些超参数来解决该问题？\n",
    "\n",
    "隐藏层数量，每层的神经元数量，学习率，激活函数类型，批量大小，训练轮数\n",
    "减少隐藏层数量或神经元数量，减少训练轮数，降低学习率，增加批量大小\n",
    "\n",
    "5. 假设有一个MLP，该MLP由一个输入层，10个特征，随后是一个包含50个神经元的隐藏层，最后是3个神经元组成的输出层。所有人工神经元都使用ReLU激活函数。\n",
    "\n",
    "   a. 输入矩阵X的形状是什么\n",
    "\n",
    "        (batch_size, 10)\n",
    "\n",
    "   b. 隐藏层的权重W_hidden及其偏置b_hidden的形状分别是什么\n",
    "        \n",
    "        W_hidden(10, 50)\n",
    "        b_hidden(50,)\n",
    "    \n",
    "   c. 输出层的权重W_output及其偏置b_output的形状是什么\n",
    "\n",
    "        W_hidden(50, 3)\n",
    "        b_output(3,)\n",
    "\n",
    "   d. 网络输出矩阵Y的形状是什么\n",
    "\n",
    "        (batch_size, 3)\n",
    "\n",
    "   e. 写出输出矩阵Y的计算公式，满足Y是W_hidden, b_hidden, W_output, b_output的函数\n",
    "   \n",
    "        Y = ReLU(ReLU(X @ W_hidden + b_hidden) @ W_output + b_output)    \n",
    "\n",
    "6. 如果要将电子邮件分类为垃圾邮件或正常邮件，需要在输出层中有多少个神经元？应该在输出层中使用什么激活函数？相反，如果想解决MNIST图片分类问题，则在输出层中需要有多少个神经元，应该使用哪种激活函数？如何使神经网络预测 回归话题里提到的房价？\n",
    "\n",
    "    1个神经元，使用sigmoid激活函数。10个神经元，使用softmax激活函数。无激活函数，使用ReLU激活函数。\n"
   ],
   "id": "efbfab39dff1fdac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 编程题",
   "id": "3a345ebdc81ebc04"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在MNIST数据集上训练深度MLP（可以使用tf.keras.datasets.mnist.load_data()加载它）。看看是否可以通过手动调整超参数获得98%以上的精度。\n",
    "\n",
    "首先尝试使用课堂上介绍的方法搜索最佳学习率（即通过以指数方式增加学习率，根据学习率变化绘制训练损失，并找到损失激增的点）。\n",
    "\n",
    "接下来，尝试使用Keras Tuner调整超参数——保存检查点，使用早停，并使用TensorBoard绘制学习曲线。"
   ],
   "id": "8ae50ffff27ba189"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T12:50:28.402860Z",
     "start_time": "2025-09-01T12:50:28.400845Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "11cdb2a45a020374",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T12:51:28.103904Z",
     "start_time": "2025-09-01T12:50:29.942864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, min_lr=1e-7, max_lr=1e-1, steps=20):\n",
    "        super(myCallback, self).__init__()\n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.steps = steps\n",
    "        self.learning_rates = []\n",
    "        self.losses = []\n",
    "        self.r = (max_lr/min_lr)**(1/(steps-1))\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        # 设置递增的学习率\n",
    "        new_lr = self.min_lr * self.r**epoch\n",
    "        optimizer = self.model.optimizer\n",
    "        optimizer.learning_rate = new_lr\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        optimizer = self.model.optimizer\n",
    "        current_lr = float(optimizer.learning_rate)\n",
    "        self.learning_rates.append(current_lr)\n",
    "        self.losses.append(logs['loss'])\n",
    "        \n",
    "    \n",
    "    def on_train_end(self, logs=None):\n",
    "        if len(self.learning_rates) > 0 and len(self.losses) > 0:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(self.learning_rates, self.losses, 'o-')\n",
    "            plt.xscale('log')\n",
    "            plt.show()\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-7)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "my_cb = myCallback()\n",
    "model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=20, \n",
    "    validation_data=(X_test, y_test), \n",
    "    callbacks=[my_cb],\n",
    "    verbose=0\n",
    ")\n"
   ],
   "id": "6643c92d5245d7e9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAAH+CAYAAABUV3s/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABbTElEQVR4nO3deXxU9b3/8ffMZJmsE5KQDQIk7CGsATQIilIRtNS91tatVStWbXu53lprb7nqbbm2/lprVayt1lqqdcEFitWCBlBB2UFkh0BCSAhJYLIxWWbO74+QSCQhk5DkzPJ6Ph7zqMycSd7xNJh3zvd8vhbDMAwBAAAAQACxmh0AAAAAALobRQcAAABAwKHoAAAAAAg4FB0AAAAAAYeiAwAAACDgUHQAAAAABByKDgAAAICAQ9EBAAAAEHBCzA7gDY/HoyNHjigmJkYWi8XsOAAAAABMYhiGqqqqlJaWJqu1/es2flF0jhw5ovT0dLNjAAAAAPARhYWF6t+/f7uvd6roLFiwQG+++aZ27dqliIgITZkyRY899piGDx/e7ntWrlypiy+++Iznd+7cqREjRnj1eWNiYiQ1fTGxsbGdiQwAAAAggFRWVio9Pb2lI7SnU0Vn1apVuueeezRp0iQ1NjbqoYce0syZM7Vjxw5FRUWd9b27d+9uVVL69u3r9edtXq4WGxtL0QEAAADQ4S0tnSo67733Xqs//+Uvf1FSUpI2btyoCy+88KzvTUpKUlxcXGc+HQAAAAB0yTlNXXM6nZKk+Pj4Do8dP368UlNTNWPGDOXl5Z312Lq6OlVWVrZ6AAAAAIC3ulx0DMPQvHnzNHXqVGVnZ7d7XGpqqp577jktXrxYb775poYPH64ZM2Zo9erV7b5nwYIFcjgcLQ8GEQAAAADoDIthGEZX3njPPfdo2bJl+vjjj8867aAtc+bMkcVi0ZIlS9p8va6uTnV1dS1/br7hyOl0co8OAAAAEMQqKyvlcDg67AZduqJz3333acmSJcrLy+t0yZGk888/X3v37m339fDw8JbBAwwgAAAAANBZnRpGYBiG7rvvPr311ltauXKlMjIyuvRJN2/erNTU1C69FwAAAAA60qmic8899+jll1/WO++8o5iYGJWUlEiSHA6HIiIiJEkPPvigioqK9NJLL0mSnnjiCQ0aNEijRo1SfX29Fi1apMWLF2vx4sXd/KUAAAAAQJNOFZ2FCxdKkqZPn97q+b/85S+67bbbJEnFxcUqKChoea2+vl7333+/ioqKFBERoVGjRmnZsmW6/PLLzy05AAAAALSjy8MIepO3NxwBAAAACGw9OowAAAAAAHwZRQcAAABAwKHoAAAAAAg4FB0AAAAAAadTU9eCndtjaF1+hUqrXEqKsWtyRrxsVovZsQAAAAB8BUXHS+9tL9bDS3eo2OlqeS7VYdf8OVmalc3mpwAAAIAvYemaF97bXqy7F21qVXIkqcTp0t2LNum97cUmJQMAAADQFopOB9weQw8v3aG2Nhtqfu7hpTvk9vj8dkQAAABA0GDpWgfW5VeccSXndIakYqdLNz//mSYM6KMBCZEaEN/0SIm1y8o9PAAAAECvo+h0oLSq/ZJzujX7y7Vmf3mr58JsVvWPj2gpPi2PhEil94lUVPi5/+tnQAIAAABwJopOB5Ji7F4d953z0mWxWFRQcVIF5TU6fPyk6t0eHThWowPHatp8T2J02FcKUFTLPyfFhHd4NYgBCQAAAEDbLIZh+PzNJZWVlXI4HHI6nYqNje3Vz+32GJr62IcqcbravE/HIinFYdfHD1zS6kqK22Oo2HlSBRW1KiivbfrfiloVVtTqUEWtTtQ2nPXzhodYlX5aCUqPj9TA064GrdpTqrsXbTojU3OChTdNoOwAAAAg4HjbDSg6XmieuiapVbE4l1LhPNmgwoovC1BLCSqvVdGJkx0ON7BapPYOaa98AQAAAP7O227A0jUvzMpO1cKbJpyxTCzlHJaJOSJC5ejnUHY/xxmvNbo9Kna6VHCq+Hx5JahGh8prVeVqbLfkSF8OSFi155guGZHU6WwAAACAv+OKTif4yo3//1hXoJ+++XmHx1ktUs7APpoyOFFThyZqXHqcQm1MFAcAAID/4opOD7BZLcodnGB2DA1MiPLqOI8hrT94XOsPHtfvP9irqDCbJmfE64IhibpgSKJGpMTIYmFpGwAAAAIPRccPTc6IV6rD3uGAhJfvOF+f5pfrk31lWrO/XBU19crbfUx5u49Japr6NmVwoi4YkqALhiSqf5/IXv06AAAAgJ7C0jU/1dkBCR6PoZ0llVqzr1wf7yvTuvwKnWxwt/qYgxIiNWVIoqYOSVRuZoL6RIX18FcBAAAAdA5T14LAueyjU9/o0eaC4/pkX5k+3lemrYedrSa9WSzSqLTYpmVugxM1aVC8IsJsXuXylXuZAAAAEHgoOkGiu0pFlatBnx2o0Cf7y/TJvjLtOVrd6vUwm1U5A/u0LHMb3c+hkDYGG7CJKQAAAHoSRQfnpLTSpTX7m5a5fbKvrFVxkaQYe4jOz0zQ1CFN9/gM7hut978oYRNTAAAA9CiKDrqNYRjKL6tpWea2dn+5Kl2NrY5JiglTlatRJxs8bX4MNjEFAABAd2C8NLqNxWJRZt9oZfaN1s25g+T2GNpe5GxZ5rb+4HGVVtWf9WM0b2K6Lr/CJ0Z0AwAAILBRdNBpNqtFY9PjNDY9Tj+YPkSuBrf+8OFePZ23v8P3lla5OjwGAAAAOFdn3k0OdJI91KapQ/p6dWwIy9YAAADQCyg66BbNm5h2VGN+/I8tmv/Odh2t5MoOAAAAeg5FB93CZrVo/pwsSTqj7DT/eUhStBo8hv669pCm/TpP/7PkC5VSeAAAANADKDroNrOyU7XwpglKcdhbPZ/isOvZmyZo+X9cqL/fcZ4mDuyj+kaPXlxzUNN+nadHlu7g3h0AAAB0K8ZLo9t1tImpYRj6eF+Zfrd8jzYVnJAk2UOtuvn8gbrrosFKjA43KTkAAAB8HfvowOcZhqHVe5sKz5bCE5KkiFCbbskdqO9fmKkECg8AAAC+gqIDv2EYhlbuOaYnlu/R1sNOSVJkmE235A7S9y/MVHxUmMkJAQAA4CsoOvA7hmEob3epfrd8rz4vaio8UWE23TplkO6clqk+FB4AAICgR9GB3zIMQyt2luqJFXv0xZFKSVJ0eIhumzJId0zLUFwkhQcAACBYUXTg9wzD0L93HNUTK/ZqZ3FT4YkJD9F3p2bo9qkZckSEmpwQAAAAvY2ig4Dh8Rj6944SPbFir3aVVEmSYuwhun1qhr43NUOxdgoPAABAsKDoIOB4PIbe+6JET6zYoz1HqyVJsfYQ3TEtU9+9YJBiKDwAAAABj6KDgOXxGHp3e7F+v2Kv9pY2FR5HRKjunJah2y7IUHR4iMkJAQAA0FMoOgh4bo+hZZ8X6/cr9mj/sRpJUlxkqO6clqnbpgxS1GmFp6NNTAEAAOAfKDoIGm6PoaVbj+jJD/bqQFlT4YmPCtP3L8zULbkDtXrPMT28dIeKna6W96Q67Jo/J0uzslPNig0AAIAuoOgg6DS6PVpyqvAcLK+V1DSWurqu8Yxjm6/lLLxpAmUHAADAj3jbDay9mAnoUSE2q66Z0F8r5l2kx68fqwHxEW2WHElqbvcPL90ht8fnuz4AAAA6iaKDgBNis+q6nP761dWjz3qcIanY6dK6/IreCQYAAIBeQ9FBwCqvqffquNIqV8cHAQAAwK9QdBCwkmLs3XocAAAA/AdFBwFrcka8Uh12nW2IdFxEqCZnxPdaJgAAAPQOig4Cls1q0fw5WZLUbtk5cbJBf//sUO+FAgAAQK+g6CCgzcpO1cKbJijF0Xp5WqrDrotH9JUk/eKdL/R03j75waR1AAAAeCmk40MA/zYrO1WXZqVoXX6FSqtcSoqxa3JGvKwW6Xcr9urJD/bqN+/vVuXJBv109ghZLGdb7AYAAAB/QNFBULBZLcodnHDG8/MuHaZYe4j+d9lO/XH1AVXVNerRK7Nls1J2AAAA/BlL1xD07piWqceuHS2LRXr5swL9x6tb1OD2mB0LAAAA54CiA0i6YdIA/eHG8QqxWrRk6xHN/dtGuRrcZscCAABAF1F0gFO+PiZNf7plosJDrPpgV6m++5f1qq5rNDsWAAAAuoCiA5zm4hFJ+uv3Jis6PERrD5TrO3/6VMdr6s2OBQAAgE6i6ABfcX5mgl6+8zz1iQzV1sNOfeu5T1Va6TI7FgAAADqBogO0YUz/OL12V66SYsK1+2iVrv/jWhVW1JodCwAAAF6i6ADtGJocozfmTlF6fIQOldfq+mfXal9ptdmxAAAA4AWKDnAWAxIi9fpdUzQ0KVollS59849rtb3IaXYsAAAAdICiA3QgxWHXq3flanQ/hypq6nXjc59q/cEKs2MBAADgLCg6gBfio8L08p3naXJGvKrqGnXz859p1Z5jZscCAABAOyg6gJdi7KH663cna/rwvnI1eHTHX9frX58Xmx0LAAAAbaDoAJ0QEWbTczdP1BVjUtXgNnTPy5v0+oZCs2MBAADgKyg6QCeFhVj15LfG61uT0uUxpP96Y5te+Djf7FgAAAA4DUUH6AKb1aIF14zWHVMzJEmP/HOHfr9irwzDMDkZAAAAJIoO0GUWi0UPXTFS//G1YZKk363Yo18u20nZAQAA8AEUHeAcWCwW/ehrQ/WLr2dJkv78cb4efPNzuT2UHQAAADNRdIBu8L2pGfr1dWNktUj/WF+oH/1js+obPWbHAgAACFoUHaCbfHNiup769gSF2iz657Zi3fW3DTpZ7zY7FgAAQFCi6ADd6PLRqfrTLRNlD7Uqb/cx3fqXdapyNZgdCwAAIOhQdIBuNn14kl763nmKCQ/RuvwKfefPn6mipt7sWAAAAEGFogP0gMkZ8Xrl++crPipM2w47dcMf1+popcvsWAAAAEGDogP0kOx+Dr121/lKibVrb2m1rnt2jQrKa82OBQAAEBQoOkAPGpIUo9fn5mpgQqQKK07q+j+u0d6jVWbHAgAACHgUHaCHpcdH6vW7cjUsOVpHK+v0zT+u1bbDJ+T2GFq7v1zvbCnS2v3l7L0DAADQjSyGH2zjXllZKYfDIafTqdjYWLPjAF1yvKZet/1lnbYedsoeYlVkeEirIQWpDrvmz8nSrOxUE1MCAAD4Nm+7AVd0gF7SJypMf7/zfA1Nipar0XPGJLYSp0t3L9qk97YXm5QQAAAgcFB0gF4UEWprd1+d5kurDy/dwTI2AACAc0TRAXrRuvwKlVTWtfu6IanY6dK6/IreCwUAABCAKDpALyqt8m4vHW+PAwAAQNsoOkAvSoqxd+txAAAAaBtFB+hFkzPileqwy3KWY1Iddk3OiO+1TAAAAIGoU0VnwYIFmjRpkmJiYpSUlKSrrrpKu3fv7vB9q1atUk5Ojux2uzIzM/Xss892OTDgz2xWi+bPyZKkdsvO/DlZslnPVoUAAADQkU4VnVWrVumee+7Rp59+quXLl6uxsVEzZ85UTU1Nu+/Jz8/X5ZdfrmnTpmnz5s362c9+ph/+8IdavHjxOYcH/NGs7FQtvGmCUhxtL0/rFxfZy4kAAAACzzltGHrs2DElJSVp1apVuvDCC9s85oEHHtCSJUu0c+fOlufmzp2rrVu3au3atV59HjYMRSByewyty69QaZVLSTF2/WPdIb2ztVgTB/bR63NzZbFwVQcAAOCrvO0GIefySZxOpyQpPr79+wnWrl2rmTNntnrusssu0/PPP6+GhgaFhoae8Z66ujrV1X05greysvJcYgI+yWa1KHdwQsufByVG6t87SrXh0HEt3Vasb4xNMzEdAACAf+vyMALDMDRv3jxNnTpV2dnZ7R5XUlKi5OTkVs8lJyersbFRZWVlbb5nwYIFcjgcLY/09PSuxgT8RqojQj+YPliStODdnTpZ7zY5EQAAgP/qctG59957tW3bNr3yyisdHvvVJTjNq+XaW5rz4IMPyul0tjwKCwu7GhPwK3demKl+cREqdrr07Kr9ZscBAADwW10qOvfdd5+WLFmivLw89e/f/6zHpqSkqKSkpNVzpaWlCgkJUUJCQpvvCQ8PV2xsbKsHEAzsoTY9dMVISdIfV+9X0YmTJicCAADwT50qOoZh6N5779Wbb76pDz/8UBkZGR2+Jzc3V8uXL2/13L///W9NnDixzftzgGA3OztFkzPi5Wrw6P/+tcvsOAAAAH6pU0Xnnnvu0aJFi/Tyyy8rJiZGJSUlKikp0cmTX/7W+cEHH9Qtt9zS8ue5c+fq0KFDmjdvnnbu3KkXXnhBzz//vO6///7u+yqAAGKxNO21Y7FIS7ce0br8CrMjAQAA+J1OFZ2FCxfK6XRq+vTpSk1NbXm8+uqrLccUFxeroKCg5c8ZGRl69913tXLlSo0bN06PPvqonnzySV177bXd91UAAWZUmkPfmjRAkvTw0i/k9nR5CjwAAEBQOqd9dHoL++ggGJVX12n64ytV5WrUY9eO1g2nig8AAEAw87YbdHnqGoCelRAdrh/NGCpJ+s37u1XlajA5EQAAgP+g6AA+7JbcQcpMjFJZdb2e+nCf2XEAAAD8BkUH8GFhIVb999ezJEkvfJKv/LIakxMBAAD4B4oO4OMuHpGk6cP7qsFt6JfLdpgdBwAAwC9QdAA/8PMrshRitWjFzlKt3nPM7DgAAAA+j6ID+IEhSdG6JXeQJOnRf+5Qg9tjbiAAAAAfR9EB/MSPZgxVfFSY9pZW6++fHjI7DgAAgE+j6AB+whEZqv+cOUyS9LsVe3W8pt7kRAAAAL6LogP4kW9NGqARKTFynmzQ71bsMTsOAACAz6LoAH7EZrVo/pxRkqRFnx7SrpJKkxMBAAD4JooO4GdyBydodnaKPIb0yNIdMgzD7EgAAAA+h6ID+KGfXT5SYSFWrdlfrn/vOGp2HAAAAJ9D0QH8UHp8pL4/LVOS9MtlO1XX6DY5EQAAgG+h6AB+6u7pg5UcG66Cilq98PFBs+MAAAD4FIoO4KeiwkP0wKwRkqSnPtyr0kqXyYkAAAB8B0UH8GNXjeuncelxqql369fv7zY7DgAAgM+g6AB+zGq1aP6cLEnSGxsPa2vhCXMDAQAA+AiKDuDnxg/oo2sm9JMkPbz0C8ZNAwAAiKIDBIQHZo1QZJhNmwpOaMnWI2bHAQAAMB1FBwgAybF23XPxEEnSgnd3qba+0eREAAAA5qLoAAHi9qkZ6t8nQiWVLj27cr/ZcQAAAExF0QEChD3Upp9fMVKS9MfVB3T4eK3JiQAAAMxD0QECyGWjUpSbmaC6Ro8W/GuX2XEAAABMQ9EBAojFYtEv5mTJapGWbSvWZwfKzY4EAABgCooOEGBGpsbqxskDJEkPL90ht4dx0wAAIPhQdIAANO/SYYq1h2hHcaVe21BodhwAAIBeR9EBAlBCdLh+/LVhkqTH39+tSleDyYkAAAB6F0UHCFA35w7U4L5RKq+p1x8+2Gt2HAAAgF5F0QECVKjNqv/+epYk6S+fHNT+Y9UmJwIAAOg9FB0ggE0fnqRLRiSp0WPol8t2mh0HAACg11B0gAD38ytGKsRq0Ye7SrVyd6nZcQAAAHoFRQcIcJl9o/XdCwZJkh795w41uD3mBgIAAOgFFB0gCNw3Y6gSosK0/1iN/rb2kNlxAAAAehxFBwgCsfZQ3X/ZcEnSEyv2qKKm3uREAAAAPYuiAwSJb05MV1ZqrCpdjfrt8t1mxwEAAOhRFB0gSNisFs2f0zRu+uXPCrSzuNLkRAAAAD2HogMEkfMyE3TF6FR5DOmRpTtkGIbZkQAAAHoERQcIMj+dPULhIVatPVCu978oMTsOAABAj6DoAEEmPT5Sd12YKUn632U75Wpwm5wIAACg+1F0gCA0d/pgpcTadfj4ST3/cb7ZcQAAALodRQcIQpFhIXrw8hGSpKfz9ulopcvkRAAAAN2LogMEqW+MTdOEAXGqrXfrsfd2mR0HAACgW1F0gCBlsVg0f84oSdKbm4q0ueC4yYkAAAC6D0UHCGJj0+N0XU5/SdLDS3fI42HcNAAACAwUHSDI/eSy4YoKs2lL4Qm9s7XI7DgAAADdgqIDBLmkWLvuuWSIJGnBuzuVt6tU72wp0tr95XJzhQcAAPgpi+EHW6NXVlbK4XDI6XQqNjbW7DhAwHE1uDX1sQ9VVl3f6vlUh13z52RpVnaqSckAAABa87YbcEUHgFbuLj2j5EhSidOluxdt0nvbi01IBQAA0HUUHSDIuT2GHl66o83Xmi/3Prx0B8vYAACAX6HoAEFuXX6Fip3tbxhqSCp2urQuv6L3QgEAAJwjig4Q5Eqr2i85XTkOAADAF1B0gCCXFGPv1uMAAAB8AUUHCHKTM+KV6rDL0s7rFjVNX5ucEd+bsQAAAM4JRQcIcjarRfPnZElSu2Vn/pws2aztvQoAAOB7KDoANCs7VQtvmqAUx5nL0x6YNYJ9dAAAgN8JMTsAAN8wKztVl2alaF1+hUqrXHptfaE+2V+uwydqzY4GAADQaVzRAdDCZrUod3CCrhzXTz+4eIgkacmWI3I1uE1OBgAA0DkUHQBtys1MUL+4CFW6GvX+FyVmxwEAAOgUig6ANlmtFl2X01+S9MbGwyanAQAA6ByKDoB2NRedj/eVqejESZPTAAAAeI+iA6Bd6fGRys1MkGFIb3JVBwAA+BGKDoCzun5i01Wd1zcelsdjmJwGAADAOxQdAGc1OztV0eEhKqio1bqDFWbHAQAA8ApFB8BZRYTZNGds04ahr29g+RoAAPAPFB0AHbouJ12S9O7nxaquazQ5DQAAQMcoOgA6NGFAnAb3jdLJBreWbTtidhwAAIAOUXQAdMhisej6iU1XdVi+BgAA/AFFB4BXrhnfTzarRRsOHdf+Y9VmxwEAADgrig4AryTF2nXRsL6SpDfYUwcAAPg4ig4Ar33z1J46b246LDd76gAAAB9G0QHgtUtGJCs+KkxHK+u0eu8xs+MAAAC0i6IDwGthIVZdOS5NkvT6hkKT0wAAALSPogOgU64/tafOih2lOl5Tb3IaAACAtlF0AHRKVlqssvvFqt7t0TtbisyOAwAA0CaKDoBOa76q8xp76gAAAB9F0QHQaVeOS1OYzaodxZX64ojT7DgAAABnoOgA6LS4yDBdOipZkvQ6V3UAAIAPougA6JLrc5r21HlnS5HqGt0mpwEAAGiNogOgS6YN7auUWLuO1zbog52lZscBAABohaIDoEtsVouumdBPEnvqAAAA39PporN69WrNmTNHaWlpslgsevvtt896/MqVK2WxWM547Nq1q6uZAfiI6yc2TV9bteeYjla6TE4DAADwpU4XnZqaGo0dO1ZPPfVUp963e/duFRcXtzyGDh3a2U8NwMdkJEZp0qA+8hjS4k0MJQAAAL4jpLNvmD17tmbPnt3pT5SUlKS4uLhOvw+Ab7s+J13rDx7XGxsO6+6LBstisZgdCQAAoPfu0Rk/frxSU1M1Y8YM5eXlnfXYuro6VVZWtnoA8E2Xj0lVRKhNB8pqtKnguNlxAAAAJPVC0UlNTdVzzz2nxYsX680339Tw4cM1Y8YMrV69ut33LFiwQA6Ho+WRnp7e0zEBdFF0eIiuGJMqiT11AACA77AYhmF0+c0Wi9566y1dddVVnXrfnDlzZLFYtGTJkjZfr6urU11dXcufKysrlZ6eLqfTqdjY2K7GBdBDPjtQrhue+1RRYTat//nXFBnW6VWxAAAAXqmsrJTD4eiwG5gyXvr888/X3r172309PDxcsbGxrR4AfNfkjHgNTIhUTb1b//q8xOw4AAAA5hSdzZs3KzU11YxPDaAHWCwWXZ/TX5L0+kb21AEAAObr9PqS6upq7du3r+XP+fn52rJli+Lj4zVgwAA9+OCDKioq0ksvvSRJeuKJJzRo0CCNGjVK9fX1WrRokRYvXqzFixd331cBwHTXTOiv/7d8jz49UKGC8loNSIg0OxIAAAhinb6is2HDBo0fP17jx4+XJM2bN0/jx4/XL37xC0lScXGxCgoKWo6vr6/X/fffrzFjxmjatGn6+OOPtWzZMl1zzTXd9CUA8AVpcRGaOiRRkvQGV3UAAIDJzmkYQW/x9oYjAOZasvWIfvjKZqU57ProgUtks7KnDgAA6F4+PYwAQGCamZWsWHuIjjhdWrO/zOw4AAAgiFF0AHQbe6hNV47rJ4k9dQAAgLkoOgC61fUTm6avvf9FiZwnG0xOAwAAghVFB0C3Gt3PoeHJMapr9Gjp1iNmxwEAAEGKogOgW1kslparOq9vYPoaAAAwB0UHQLe7enw/hVgt2nrYqT1Hq8yOAwAAghBFB0C3S4gO1yUjkiRxVQcAAJiDogOgR3xzYrok6a3NRWpwe0xOAwAAgg1FB0CPmD68rxKjw1VWXa+8XaVmxwEAAEGGogOgR4TYrLpmwqk9dTaypw4AAOhdFB0APeb6nKbpa3m7SnWsqs7kNAAAIJhQdAD0mKHJMRqXHqdGj6G3NxeZHQcAAAQRig6AHtWyp87GQhmGYXIaAADQWW6PobX7y/XOliKt3V8ut8c//nseYnYAAIFtztg0PbJ0h/Ycrda2w06NTY8zOxIAAPDSe9uL9fDSHSp2ulqeS3XYNX9OlmZlp5qYrGNc0QHQo2LtoZqdnSJJeo09dQAA8BvvbS/W3Ys2tSo5klTidOnuRZv03vZik5J5h6IDoMddf2pPnSVbj8jV4DY5DQAA6IjbY+jhpTvU1iK15uceXrrDp5exUXQA9LjczAT1i4tQlatR739RYnYcAADQgXX5FWdcyTmdIanY6dK6/IreC9VJFB0APc5qtejaU6OmX9/AnjoAAPi60qr2S05XjjMDRQdAr2jeU+eT/WUqOnHS5DQAAOBskmLs3XqcGSg6AHpFenykcjMTZBjS4o1c1QEAwJdNzohXqsMuSzuvW9Q0fW1yRnxvxuoUig6AXtO8p84bGw/L48M3LwIAEOxsVovmz8lqcxhBc/mZPydLNmt7Vch8FB0AvWZ2dqqiw0NUUFGrz3z45kUAACDNyk7VeW1csUlx2LXwpgk+v48OG4YC6DURYTbNGZuqV9YV6vWNhcodnGB2JAAA0A6Px9C+0mpJ0s+vGKm+MeFKimlarubLV3KacUUHQK+6LqdpT51/fV6iKleDyWkAAEB7Pi9yqrymXtHhIbold5CuHNdPuYMT/KLkSBQdAL1swoA4ZfaN0skGt5Zt8+0dlQEACGZ5u0slSVOHJCosxP9qg/8lBuDXLBaLvjmx6arO60xfAwDAZ63cfUySdPGIviYn6RqKDoBed834frJZLdp46Lj2H6s2Ow4AAPiK8uo6bT18QpJ00bAkc8N0EUUHQK9LirXromFNvx16g6s6AAD4nNV7j8kwpJGpsUpx+O6moGdD0QFgiutzmvbUWbzxsBrdHpPTAACA0+XtOrVsbbh/LluTKDoATDJjZLLio8JUWlWnj/aWmR0HAACc4vYYWr23+f4c/1y2JlF0AJgkLMSqK8elSZJe31hochoAANBsS+EJnahtUKw9ROPT48yO02UUHQCmuf7UnjrLdxxVRU29yWkAAIAkrTw1VvrCYX0VYvPfuuC/yQH4vay0WI1Ki1WD29A7W4rMjgMAAPTl/jnTh/vvsjWJogPAZC176mxg+hoAAGYrrXRpe1GlJLVMSPVXFB0AprpyXJrCbFbtKK7U9iKn2XEAAAhqK/c0DSEY09+hvjHhJqc5NxQdAKaKiwzTpVnJkthTBwAAs60MkGVrEkUHgA+4fmLTnjpvbylSXaPb5DQAAASnBrenZcsHf94/pxlFB4Dppg3tq5RYu07UNuiDnaVmxwEAIChtOnRcVa5GxUeFaUz/OLPjnDOKDgDT2awWXTOhnyTptQ3sqQMAgBnydjfdn3Ph0ETZrBaT05w7ig4An3BdTtPytdV7jqnE6TI5DQAAwaf5/pyLR/j//TkSRQeAj8jsG61Jg/rIY0hvbmYoAQAAvenIiZPaVVIli0W6cKj/358jUXQA+JDrc77cU8cwDJPTAAAQPFaeWrY2Pj1OfaLCTE7TPSg6AHzG5WNSFRFqU35ZjTYeOm52HAAAgkbLsrUAGCvdjKIDwGdEh4foijGpkpqu6gAAgJ5X1+jWJ/tOjZUOkPtzJIoOAB9z/amhBP/cdkS19Y0mpwEAIPBtOHhcNfVuJUaHKys11uw43YaiA8CnTM6I18CESNXUu/Xu5yVmxwEAIODl7WpatjZ9eF9ZA2CsdDOKDgCfYrFYdN2Epqs6r7OnDgAAPS4vAO/PkSg6AHzQtTn9ZbFIn+VX6FB5jdlxAAAIWIUVtdp/rEY2q0VThyaaHadbUXQA+Jy0uAhNHdL0l+0bGxlKAABAT2metpYzsI8cEaEmp+leFB0APun6iU176izeeFhuD3vqAADQE/JO7Z8TaMvWJIoOAB81MytZsfYQHXG6tGZ/mdlxAAAIOK4Gd8t/Y6cP72tymu5H0QHgk+yhNl05rp8k9tQBAKAnfHqgXK4Gj1Ji7RqREmN2nG5H0QHgs66f2DR97V/bi7Vix1G9s6VIa/eXs5QNAIBusLJ52dqIvrJYAmesdLMQswMAQHtG93MozWHXEadLd7y0oeX5VIdd8+dkaVZ2qonpAADwb82DCKYH4P05Eld0APiw978o0RGn64znS5wu3b1ok97bXmxCKgAA/F9+WY0Oltcq1GbRBUMCa6x0M4oOAJ/k9hh6eOmONl9rXrj28NIdLGMDAKAL8nY1Xc2ZnBGv6PDAXORF0QHgk9blV6i4jas5zQxJxU6X1uVX9F4oAAACRF7zsrVhgblsTaLoAPBRpVXtl5yuHAcAAJrU1jfqswNNvyi8eETgjZVuRtEB4JOSYuzdehwAAGiyZl+56t0e9e8TocF9o82O02MoOgB80uSMeKU67Gpv2KVFTdPXJmfE92YsAAD83so9TcvWLh6eFJBjpZtRdAD4JJvVovlzsiSp3bIzf06WbNbA/QsaAIDuZhiG8nZ9uX9OIKPoAPBZs7JTtfCmCUpxtF6eFmqzaOFNE9hHBwCATtpXWq2iEycVFmJVbmZgjpVuFpiz5AAEjFnZqbo0K0Xr8iu0r7RK/7P0CzW4DaU6IsyOBgCA32metnZ+ZoIiwmwmp+lZXNEB4PNsVotyByfo5txBunJsP0nS8x/nm5wKAAD/07JsbXhgL1uTKDoA/Mz3pmZIkpZ9XqwjJ06anAYAAP9R5WrQhkOnxkoPD9z9c5pRdAD4lex+Dp2XES+3x9Bf1x40Ow4AAH7jk33lanAbykiM0qDEKLPj9DiKDgC/c8e0TEnSK58VqKau0eQ0AAD4h5Wn7s+ZHgTL1iSKDgA/NGNEkgYlRKrS1ajFmw6bHQcAAJ9nGEbLIIJgWLYmUXQA+CGr1aLvXtB0r84LH+fL4zFMTgQAgG/bWVylo5V1igi1Bc1m2xQdAH7pupz+irWH6GB5rT7YVWp2HAAAfFrz1ZwpgxNkDw3ssdLNKDoA/FJUeIhuPG+AJOn5jw+YnAYAAN+2anfTWOnpI4Jj2ZpE0QHgx27NHSSb1aJPD1ToiyNOs+MAAOCTnLUN2lhwXJI0fVhwDCKQKDoA/FhaXIQuH50qiQ1EAQBoz0f7jsntMTQ0KVrp8ZFmx+k1FB0Afu32UxuILt16RKWVLpPTAADge/J2NS1buziIlq1JFB0Afm5cepxyBvZRg9vQS2sPmR0HAACf4vEYWrXn1P45QbRsTaLoAAgAd5y6qvP3zw7J1eA2OQ0AAL5j+xGnyqrrFRVm08RBwTFWuhlFB4DfmzkqRf37ROh4bYPe3FRkdhwAAHzGylPT1qYOTVRYSHD96B9cXy2AgGSzWnTblEGSmkZNs4EoAABNmvfPuXh4cN2fI1F0AASIGyalKzo8RPuP1WjV3mNmxwEAwHQVNfXaUnhCkjSdogMA/inGHqobJqVLkl5g1DQAAFq955gMQxqZGqsUh93sOL2u00Vn9erVmjNnjtLS0mSxWPT22293+J5Vq1YpJydHdrtdmZmZevbZZ7uSFQDO6rYpg2S1SB/tLdPukiqz4wAAYKrmZWvThwfXtLVmnS46NTU1Gjt2rJ566imvjs/Pz9fll1+uadOmafPmzfrZz36mH/7wh1q8eHGnwwLA2aTHR+qyUSmSuKoDAAhubo+hVXtO7Z8ThMvWJCmks2+YPXu2Zs+e7fXxzz77rAYMGKAnnnhCkjRy5Eht2LBBjz/+uK699trOfnoAOKvbp2boX9tL9NaWIv3XrOFKjA43OxIAAL1u6+ETOlHboBh7iCYMiDM7jil6/B6dtWvXaubMma2eu+yyy7RhwwY1NDS0+Z66ujpVVla2egCAN3IG9tHY9DjVN3q06FM2EAUABKeVu5qWrV04rK9CbMF5W36Pf9UlJSVKTk5u9VxycrIaGxtVVlbW5nsWLFggh8PR8khPT+/pmAAChMVi0e2nNhBd9CkbiAIAglPe7uBetib10tQ1i8XS6s+GYbT5fLMHH3xQTqez5VFYWNjjGQEEjtnZKUp12FVWXa8lW4+YHQcAgF5VWuXS50VOSdJFw4JzEIHUC0UnJSVFJSUlrZ4rLS1VSEiIEhIS2nxPeHi4YmNjWz0AwFuhNqtuPbWB6Asf57f8cgUAgGCw6tTVnNH9HOobE7z3qvZ40cnNzdXy5ctbPffvf/9bEydOVGhoaE9/egBB6sZJAxQRatOukip9sq/c7DgAAPSalS3T1oL3ao7UhaJTXV2tLVu2aMuWLZKaxkdv2bJFBQUFkpqWnd1yyy0tx8+dO1eHDh3SvHnztHPnTr3wwgt6/vnndf/993fPVwAAbXBEhuqbE/tLkp7/+IDJaQAA6B2Nbo9Wnyo600cE7/05UheKzoYNGzR+/HiNHz9ekjRv3jyNHz9ev/jFLyRJxcXFLaVHkjIyMvTuu+9q5cqVGjdunB599FE9+eSTjJYG0OO+e0GGLJamGzL3lVabHQcAgB63qeCEqlyN6hMZqrH948yOY6pO76Mzffr0s653f/HFF8947qKLLtKmTZs6+6kA4JwMSozSjBHJWrHzqP7ySb5+efVosyMBANCj8nY3jZW+aFhf2axtD/4KFsE5VBtA0GgeNb1402Edr6k3OQ0AAD0r79T+OdODeKx0M4oOgIB2fma8RqXFytXg0cvrCjp+AwAAfqrYeVK7SqpksTRtFBrsKDoAAtrpG4j+dc1B1Td6TE4EAEDPaB4rPS49TvFRYSanMR9FB0DA+/qYNCXFhKu0qk7LPmcDUQBAYGq+P+dilq1JougACAJhIVbdkjtQkvQ8G4gCAAJQfaNHH+8tk0TRaUbRARAUvn3eQIWHWLW9qFKf5VeYHQcAgG614WCFaurdSowO16i0WLPj+ASKDoCgEB8VpmtzmjcQzTc5DQAA3ev0sdLWIB8r3YyiAyBofO+CpqEEK3Ye1cGyGpPTAADQffJODSK4eATT1ppRdAAEjSFJ0Zo+vK8MQ3pxzUGz4wAA0C0KK2q1r7RaNqtF04ZQdJpRdAAEleZR069tKJTzZIPJaQAAOHcr9zRdzckZ0EeOyFCT0/gOig6AoDJ1SKKGJ8eott6tf7CBKAAgAKzc1XR/znSWrbVC0QEQVL66gWijmw1EAQD+y9Xg1if7GSvdFooOgKDzjXFpSowO0xGnS//aXmJ2HAAAuuyz/Aq5GjxKibVrREqM2XF8CkUHQNCxh9r0nfOaNhD9MxuIAgD82MpTY6WnD+8ri4Wx0qej6AAISjedP1BhIVZtLTyhTQXHzY4DAECXrDw1Vno6y9bOQNEBEJT6xoTrqnFpkthAFADgn/LLapRfVqNQm0UXDEkwO47PoegACFrfOzWU4L3tJSqsqDU5DQAAndO8bG3SoHjF2Bkr/VUUHQBBa0RKrKYOSZTHaJrABgCAP8k7tWyNaWtto+gACGrNo6ZfXV+oKhcbiAIA/MPJerc+PVAuqWkQAc5E0QEQ1C4a1leD+0apqq5Rr204bHYcAAC8svZAmeobPeoXF6EhSdFmx/FJFB0AQc1qtbTcq/Pimny5PYyaBgD4vrxdp5atjWCsdHsoOgCC3jXj+ysuMlSFFSe1fAcbiAIAfJthGMo7NYiA+3PaR9EBEPQiwmz6znkDJDFqGgDg+/Yfq9bh4ycVFmJV7mDGSreHogMAkm7JHaRQm0XrDx7X1sITZscBAKBdzcvWzs9MUGRYiMlpfBdFBwAkJcfaNWcMG4gCAHxf87K16cOYtnY2FB0AOKV5KMG7nxer2HnS5DQAAJypuq5R6w9WSJIuHsH9OWdD0QGAU7L7OXReRrwaPYb+uuaQ2XEAADjDJ/vK1OA2NCghUhmJUWbH8WkUHQA4TfMGoi9/dkg1dY0mpwEAoLWVzcvWmLbWIYoOAJxmxshkDUqIVKWrUYs3sYEoAMB3GIZx2v45FJ2OUHQA4DQ2q0XfvaDpqs5fPjkoDxuIAgB8xK6SKpVUumQPteq8jHiz4/g8ig4AfMV1Of0Vaw9RflmNPtxVanYcAAAkSSt3N13NmTI4UfZQm8lpfB9FBwC+Iio8RDdOZgNRAIBvaR4rffFwxkp7g6IDAG24dcog2awWrT1Qri+OOM2OAwAIcs6TDdp46LgkBhF4i6IDAG1Ii4vQ5aNTJXFVBwBgvo/3lsntMTQkKVrp8ZFmx/ELFB0AaEfzqOmlW4+otNJlchoAQDBj2VrnUXQAoB3j0uOUM7CPGtyG/vYpG4gCAMzh8RgtgwguZtma1yg6AHAWzVd1Fn16SK4Gt8lpAADBaEdxpcqq6xQVZtPEQYyV9hZFBwDOYmZWsvr3idDx2ga9uanI7DgAgCCUd2qrgwuGJCoshB/fvcW/KQA4ixCbVbdNGSRJeuGTfBkGG4gCAHpXy/05I1i21hkUHQDowA2T0hUdHqJ9pdVateeY2XEAAEGkoqZemwtPSJKmM4igUyg6ANCBGHuovjkxXRKjpgEAveujvcdkGNKIlBilOiLMjuNXKDoA4IXvXjBIVov00d4y7S6pMjsOACBINN+fw7K1zqPoAIAX0uMjddmoFEnSC1zVAQD0ArfH0Oq9ZZKk6cNYttZZFB0A8FLzqOm3thSprLrO5DQAgEC37fAJVdTUK8YeogkD+5gdx+9QdADASzkD+2hsf4fqGz36+6cFZscBAAS4vFObhF44tK9CbfzY3ln8GwMAL1ksFt0+LVOS9NLafK3aU6p3thRp7f5yuT2MnQYAdK+Vp8ZKM22ta0LMDgAA/mR2doriIkNVXtOgW19Y3/J8qsOu+XOyNCs71cR0AIBAcayqTtsOOyVJF1F0uoQrOgDQCR/sPKoTtQ1nPF/idOnuRZv03vZiE1IBAALN6lP7to3u51BSjN3kNP6JogMAXnJ7DD28dEebrzUvXHt46Q6WsQEAzlkey9bOGUUHALy0Lr9CxU5Xu68bkoqdLq3Lr+i9UACAgNPo9rRc0Zk+nP1zuoqiAwBeKq1qv+R05TgAAL7K7TG06NNDqnQ1KircptH9HGZH8lsUHQDwkrdrpFlLDQDoive2F2vqYx/qf04tk66pc+ui3+Rx/2cXUXQAwEuTM+KV6rDLcpZjUh12Tc6I77VMAIDA8N72Yt29aNMZS6QZdtN1FB0A8JLNatH8OVmS1G7ZuWZCP9msZ6tCAAC01jzspq1RNgy76TqKDgB0wqzsVC28aYJSHK2Xp0WE2iRJL35yUDuLK82IBgDwUwy76RlsGAoAnTQrO1WXZqVoXX6FSqtcSoqxa1x6nL734nqtPVCu219cr7fvvYB7dQAAXmHYTc/gig4AdIHNalHu4ARdOa6fcgcnKCLMpmdvylFm3ygdcbp051836GS92+yYAAA/wLCbnkHRAYBu4ogM1Qu3TlKfyFBtPezUvNe2yMN6agBAByZnxCsyzNbu6xYx7KYrKDoA0I0GJUbpjzdPVJjNqn9tL9Fv/r3b7EgAAB+3YudR1bazCqB5vM38OVkMu+kkig4AdLPJGfF67LrRkqSFK/frtfWFJicCAPiqohMn9ZM3tkmSLs1KVupXht2kOOxaeNMEzcpONSOeX2MYAQD0gKvH91d+Wa2e/GCvfvbW5+rfJ0JThiSaHQsA4EMa3B798JXNcp5s0Nj0OD397QmyWS2tht1MzojnSk4XcUUHAHrIf3xtqL4xNk2NHkNzF23UvtJqsyMBAHzIb5fv0cZDxxVjD9FTN45XWIj1jGE3lJyuo+gAQA+xWCz69XVjlDOwjypdjfrei+tVUVNvdiwAgA9YveeYFq7cL0l67NoxSo+PNDlR4KHoAEAPsofa9NzNOUqPj1BBRa2+/9IG1TUydhoAgllppUvzXtsiSbrp/AG6fDT33/QEig4A9LCE6HD95bZJirGHaMOh43rgjW0yDMZOA0AwcnsM/fjVLSqrrteIlBj9/IossyMFLIoOAPSCIUkxevamHIVYLXp7yxE9+cE+syMBAEzwTN4+rdlfrsgwm5769gTZQ9vfPwfnhqIDAL3kgiGJevSqbEnS71bs0TtbikxOBADoTevyK/S7FXskSY9ema0hSdEmJwpsFB0A6EU3Th6guy7MlCT91+vbtOFghcmJAAC9oaKmXj98ZbM8hnTNhH66Nqe/2ZECHkUHAHrZA7NGaGZWsurdHn3/bxt1qLzG7EgAgB5kGIb+6/WtKql0KbNvlB69MtvsSEGBogMAvcxqteiJb43T6H4OVdTU63svrpeztsHsWACAHvL8x/n6YFepwkKsevrbExQVHmJ2pKBA0QEAE0SGhejPt05UqsOu/cdqdPffN6rB7TE7FgCgm20tPKHH3tslSfrvr2dpZGqsyYmCB0UHAEySHGvX87dOUlSYTWv2l+vnb21n7DQABJBKV4PufWWTGtyGLh+dopvOG2B2pKBC0QEAE2WlxeoP3x4vq0V6dUOhnlt9wOxIAIBuYBiGHnzzcxVWnFT/PhFacM0YWSwWs2MFFYoOAJjskhHJ+sXXmzaM+7/3dum97cUmJwIAnKuX1xVo2bZihVgteurbE+SICDU7UtCh6ACAD7jtggzdmjtQhiH9+NUt2lp4wuxIAIAu2lVSqUeW7pDUNGlzXHqcuYGCFEUHAHzEf389S9OH95WrwaM7XtqgohMnzY4EAOik2vpG3fP3Tapr9Oji4X11+9QMsyMFLYoOAPiIEJtVf7hxvEakxOhYVZ1uf3G9qlyMnQYAf/KLd77Q/mM1So4N1//75jhZrdyXYxaKDgD4kBh7qJ6/bZL6xoRrV0mV7ntlsxoZOw0AfuGtzYf1xsbDslqk339rvOKjwsyOFNQoOgDgY/rFRejPt0yUPdSqlbuP6X+X7TQ7EgCgAweOVeuht7ZLkn40Y5jOz0wwORG6VHSeeeYZZWRkyG63KycnRx999FG7x65cuVIWi+WMx65du7ocGgAC3dj0OD1xwzhJ0otrDurFT/LNDQQAaJerwa17Xt6s2nq3cjMTdO8lQ8yOBHWh6Lz66qv68Y9/rIceekibN2/WtGnTNHv2bBUUFJz1fbt371ZxcXHLY+jQoV0ODQDBYFZ2qn46e4Qk6ZF/7lDerlKTEwEA2vKrd3dqZ3GlEqLC9MS3xsnGfTk+odNF57e//a1uv/123XHHHRo5cqSeeOIJpaena+HChWd9X1JSklJSUloeNputy6EBIFjcdWGmbpiYLo8h3fvyJu0srjQ7EgDgNO9tL9ZLaw9Jkv7fN8cqOdZuciI061TRqa+v18aNGzVz5sxWz8+cOVNr1qw563vHjx+v1NRUzZgxQ3l5eZ1PCgBByGKx6NGrsjVlcIJq6t26/cX1Kq10mR0LACCpsKJW//XGNknSXRdlavrwJJMT4XSdKjplZWVyu91KTk5u9XxycrJKSkrafE9qaqqee+45LV68WG+++aaGDx+uGTNmaPXq1e1+nrq6OlVWVrZ6AECwCguxauF3cpTZN0pHnC7d/tcNqq1vNDsWAAS1BrdHP/zHZlW5GjV+QJzunznc7Ej4ii4NI7BYWq87NAzjjOeaDR8+XHfeeacmTJig3NxcPfPMM7riiiv0+OOPt/vxFyxYIIfD0fJIT0/vSkwACBiOyFD95bZJ6hMZqs+LnPqPV7fI4zHMjgUAQevxf+/W5oITirWH6MlvjVeojWHGvqZTZyQxMVE2m+2MqzelpaVnXOU5m/PPP1979+5t9/UHH3xQTqez5VFYWNiZmAAQkAYmROm5WyYqzGbV+18c1WPvM70SAMywcnep/rjqgCTp19eNUXp8pMmJ0JZOFZ2wsDDl5ORo+fLlrZ5fvny5pkyZ4vXH2bx5s1JTU9t9PTw8XLGxsa0eAABp0qB4/eb6MZKkP646oH+sO/vESwBA9zpa6dK817ZKkm7JHahZ2e3/TAtzhXT2DfPmzdPNN9+siRMnKjc3V88995wKCgo0d+5cSU1XY4qKivTSSy9Jkp544gkNGjRIo0aNUn19vRYtWqTFixdr8eLF3fuVAECQuHJcP+WX1eiJFXv187e3Kz0+UhcMSTQ7FgAEPLfH0I//sUUVNfXKSo3Vzy4faXYknEWni84NN9yg8vJyPfLIIyouLlZ2drbeffddDRw4UJJUXFzcak+d+vp63X///SoqKlJERIRGjRqlZcuW6fLLL+++rwIAgsyPZgxVflmN3tlyRHMXbdRbP5iijMRorcuvUGmVS0kxdk3OiGcvBwDoRk99uE9rD5QrMsymp749XvZQtkvxZRbDMHz+btbKyko5HA45nU6WsQHAKa4Gt27682facOi4EqLDZLNYVFpV1/J6qsOu+XOyWFYBAN3g0wPl+vafPpXHkH53w1hdPb6/2ZGClrfdgPEQAOCn7KE2/fHmHCVGh6m8ur5VyZGkEqdLdy/apPe2F5uUEAACQ3l1nX70j83yGNL1Of0pOX6CogMAfiwuMqzd15ov1z+8dIfcjKIGgC7xeAz95+tbdbSyTkOSovXwlaPMjgQvUXQAwI+ty69QWXV9u68bkoqdLq3Lr+i9UAAQQP788QGt3H1M4SFWPfXt8YoM6/Qt7jAJRQcA/FhplatbjwMAfGlzwXH9+r3dkqT5c0ZpRAr3ivsTig4A+LGkGLuXx4X3cBIACCzOkw2675XNavQYumJMqm6cnG52JHQSRQcA/NjkjHilOuzqaIj0Myv3a8/Rql7JBAD+zjAM/XTxNh0+flID4iO14JrRslgY1+9vKDoA4MdsVovmz8mSpDPKjqXlGOmjvWWa/fuP9N9vb1dFTfv39AAApEWfFehf20sUarPoDzeOV6w91OxI6AKKDgD4uVnZqVp40wSlOFovY0tx2PXsTRP0wbzpumxUstweQ3/79JAu+k2e/vzRAdU3ekxKDAC+a8eRSj36zx2SpAdmjdDY9DhzA6HL2DAUAAKE22NoXX6FSqtcSoqxa3JGvGzWL6/zrNlfpkf/uVM7iyslSRmJUfrZ5SP1tZFJLMkAAEk1dY2a84ePdaCsRjNGJOnPt07k70cf5G03oOgAQBBxewy9sbFQv3l/j8qqmzYYvWBIgn5+RZZGpvL3K4DgNu+1LXpzU5FSYu1690fTFB/V/l5lMA9FBwDQripXg55ZuV/Pf5SverdHVot0w6QB+s+Zw5QYzYQ2AIHvq1fBC4/X6idvbJPVIv3j+7manBFvdkS0g6IDAOhQYUWt/u9fu7Ts82JJUkx4iO69ZIhuu2CQwkNsJqcDgJ7x3vZiPbx0h4qdZ+4x9p+XDtN9M4aakAre8rYbMIwAAIJYenyknv7OBL12V66y+8Wqqq5RC/61S5f+drXe214sP/hdGAB0ynvbi3X3ok1tlhxJGtw3upcToadQdAAAmpwRryX3TNXj149VUky4CipqNXfRJn3ruU+1vchpdjwA6BZuj6GHl+7Q2X6F8+iyHXJ7+CVPIKDoAAAkSVarRdfl9Ffe/dN13yVDFB5i1Wf5FZrz1Mf6yRtbVVrZ9m8/AcBfrMuvaPdKTrNip0vr8it6KRF6EkUHANBKVHiI/nPmcH14/3R9Y2yaDEN6bcNhXfz4Sj2dt0+uBrfZEQGgS0qrvPuFjbfHwbdRdAAAbeoXF6EnbxyvxXfnamx6nGrq3frN+7s14/+t0j+3HeH+HQB+JynG3vFBnTgOvo2iAwA4q5yB8Xrr7il64oZxSom1q+jESd378mZd/+xabTt8wux4AOC1QYmRCrW1vwGoRVKqw85o6QBB0QEAdMhqteiq8f304f0X6cdfG6qIUJs2HDqubzz1iea9tkUlHax5BwCz7Syu1LXPrFGDu+2r0c31Z/6cLNms7Zch+A/20QEAdFqx86R+895uvbm5SJIUEWrT3IsG6/sXZioi7Mv9d766Id/kjHh+gADQ6z7cdVT3vbxZNfVuZSZG6bYpg7Rw1f5WgwlSHXbNn5OlWdmpJiaFN9gwFADQ47YUntAjS7/QpoITkpp+UPjp7BH6xtg0vf9FyRkb8vGDBIDeZBiGXvjkoH65bIc8hjRlcIIWfidHjshQfhHjxyg6AIBeYRiG/rmtWP/3r10qOnFSkpSRGKn8stozjm3+EWLhTRMoOwB6VIPbo/9Z8oX+/lmBJOnGyel65Mpshdq4c8PfedsNONMAgHNisVg0Z2yaPvjPi3T/zGGKCLW2WXIktWzS9/BSNuQD0HOcJxv0vRfX6++fFchikR66fKR+dfVoSk6Q4WwDALqFPdSmey8Zqt9+c9xZjzPEhnwAek5Bea2uXbhGH+0tU0SoTX+8KUd3Xpgpi4VlacEmxOwAAIDAUu/2eHUcG/IB6G4bDlbo+3/bqIqaeqXE2vXnWycqu5/D7FgwCUUHANCtvN1o78kP9qqipl5fH5OmvjHhPZwKQKB7a/NhPfDG56p3ezS6n0N/vnWikmPZ+DOYMYwAANCt3B5DUx/7UCVOl7z5D4zNatEFQxJ11bg0zRyVouhwfgcHwHsej6HfrdijP3y4T5I0a1SKfnvDWEWG8XdJoGLqGgDANO9tL9bdizZJUquy07xC/v+uHaPa+ka9veWIthaeaHndHmrVpVkpumpcmi4c1pcbhwGclavBrf98fauWbSuWJM29aLB+ctlwWRkTHdAoOgAAU723vdirfXTyy2r0zpYivbPliPLLalqe7xMZqivGpOqqcf2UM7APNxIDaKW0yqU7X9qorYUnFGK16FfXjNY3J6abHQu9gKIDADBdZzbkMwxD2w479faWIi3dWqyy6rqW1/r3idCV49J01bh+Gpoc01vxAfioXSWVuv3FDSo6cVJxkaFa+J0c5Q5OMDsWeglFBwDgtxrdHq3ZX663txTp/e0lqql3t7yWlRqrq8an6Rtj+ynFwY3GQLDJ21Wqe1/epJp6tzISo/TCbZOUkRhldiz0IooOACAgnKx3a8XOo3pnS5FW7j6mxlMbjVos0vkZCbpqfJpmZafKERFqclIAPckwDL245qAe/ecOeQzp/Mx4PXtTjuIiw8yOhl5G0QEABJzjNfVa9nmx3tlSpPUHj7c8HxZi1SXDk3TV+DRNH54ke6it3Y/RmeV0AHxDo9ujh5fu0N8+PSRJ+ubE/vrfq0YrLISBJcGIogMACGiFFbVasvWI3tlSpD1Hq1uej7GH6PLsVF05Pk3nZyS0mr7k7YAEAL6j0tWge/6+SR/tLZPFIv101gh9/8JMBpQEMYoOACAoGIahncVVLZPbSiq/LDEpsXZ9Y1yarhyXpoLyWv3g75vO2Nun+UelhTdNoOwAPqawolbfe3G99pZWKyLUpie+NU6XjUoxOxZMRtEBAAQdj8fQZ/kVemdLkZZ9XqwqV2PLayFWS8v9PV9lkZTisOvjBy5hGRvgIzYeqtD3X9qo8pp6JceG6/lbJym7n8PsWPABFB0AQFCra3Qrb9cxvbOlSMt3HG235JzulTvPZ0Qt4APe3lykn7yxTfVuj0alxer5WycxZREtvO0GIb2YCQCAXhMeYtOs7BTNyk7RP9YV6Kdvft7he46etuwNQO8zDEO/W7FXT36wV5I0MytZT3xrnCLD+JEVncf/awAAAW9ggnd7bMxf8oU+yy/X10Ym64IhiWed3gage7ka3PqvN7Zp6dYjkqS7LsrUA5eNaDVQBOgMig4AIOBNzohXqsOuEqfrjGEEzSySnCcb9Mq6Qr2yrlD2UKumDumrS7OSdPGIJCXFsGwG6CnHqur0/b9t0OaCEwqxWvTLq7N1w6QBZseCn+MeHQBAUHhve7HuXrRJklqVnebfFT954zg5IsK0YudRrdhxVEecrZexjUuP06VZyfrayGQNS45mtC3QTXaXVOl7L65X0YmTckSEauFNEzRlcKLZseDDGEYAAMBXeLuPTvPI6hU7j2rFzqPadtjZ6uP07xOhr41M1qVZyZqcEa9QG5sWAl2Rt7tU9728WdV1jRqUEKkXbpukzL7RZseCj6PoAADQBrfH0Lr8CpVWuZQUY9fkjPgOR0ofrXTpg52lWrHzqD7ZV6a6Rk/LazH2EF00rK8uzUrW9GFJckSG9vSXAPidtr7v/rb2oB755w55DOm8jHg9e1OO+kSFmR0VfoCiAwBAD6itb9THe8u0YudRfbirVGXV9S2v2awWTRrUp+Vqj7dDEIBA1taV1Mgwm2rr3ZKk63P665dXj1ZYCFdG4R2KDgAAPczjMbTl8Amt2NG0xG3P0epWrw9Jij5VepI0Lr1Pu1eOunKVCfAHzffGtffD5lXj+ul3N4zlnjd0CkUHAIBeVlBe23Jfz7r8ilablCZEheniEUn62shkTRuaqKjwpsGn3t43BPgbt8fQ1Mc+bPX/7a9Kddj18QOXUOzRKRQdAABM5DzZoFV7jmnFjqPK212qKldjy2thIVZNGZygVIddr6wrPOO9zT/yLbxpAmUHfmvt/nLd+KdPOzzulTvPV+7ghF5IhEDhbTdgHx0AAHqAIyJU3xibpm+MTVOD26P1+RVasbNUy3eWqLDipFbuPtbuew01lZ2Hl+7QpVkp/LYbfqXS1aB/fV6s51Yf8Or40qr2r/gA54KiAwBADwu1WTVlSKKmDEnUf399pPaWVuuFj/P1j/VnXs1pZkgqdrq0Lr9cuewpAh/X4PZo9Z5jenNzkVbsONpqMmFH2IwXPYWiAwBAL7JYLBqWHKPcwQlnLTrNvv/SRl08IklTBifogiGJSo+P7IWUQMcMw9C2w069tblIS7ceUXnNlxMIhyZF68rxaXppzSEdq6prcxiBRVKKo2n4BtATKDoAAJjA299iV9U1asnWI1qy9Yikps1Km0tPbmaCkmL5bTh61+HjtXp7c5He3FykA8dqWp5PjA7TN8b20zUT+mlUWqwsFouG9I3W3Ys2ySK1KjvNizHnz8liaSZ6DMMIAAAwQfNEqhKnq93fdic77Prt9WP1aX6F1uwr05bCE60muUlNI6wvGJyg3MGJOj8zXnGRbLiI7lfpatC724r15uYircuvaHneHmrVzKwUXT2hn6YNSVSI7cy9cJgsiO7G1DUAAHxc8x4jUtu/7f7q1LWaukatP1ihNfvLtWZ/mb44UqnT/ytusUjZaQ5NGZyg3MEJmjQovmWMNdBZDW6PVu0+prc2F2n5zqOqP3XfjcUi5WYm6Orx/TQrO0Ux9tAOPxZ7RaE7UXQAAPAD5/Lb7hO19fr0QPmp4lOufaWtNywNsVo0fkCccgcnasrgBI0fEKfwEJtXufjBNDgZhqGth516a9NhLd1WrIrT7rsZlhytq8f315Xj0pQWF2FiSgQ7ig4AAH6iu0rF0UqX1p662vPJvnIVnTjZ6nV7qFWTBsUrd3CCLhicqOx+jjY/D0uNgk9hRdN9N29t+ep9N+G6clyarh7/5X03gNkoOgAABDHDMFRYcVJr9pe1XPEpq65rdUyMPUTnZSTogiEJmjI4UcOSo/X+FyW6e9GmM+4bYhNT/+FtcXaebNC7nxfrrU1FWnew9X03l41K0dXj+2lqO/fdAGai6AAAgBaGYWhvabXW7CvTJ/vL9emBclW5GlsdkxAVqpp6t1wNbe+B0jwO+OMHLmEZm4/q6GpcfaNHq/Yc01ubD2vFztJW991MGZygq8f316zsFEVzbxd8GEUHAAC0y+0x9MURp9bsL9cn+8q0/mBFuwXnq16583zlDk7o4YTorObhFm1djTMkTR/WV1sPn9Dx2oaW15rvu7lqfJpSHdx3A/9A0QEAAF6ra3Tr6bz9evKDvR0emxIbrgkD+2hI32gNSY7RkL7RyuwbJXuod4MO0P2ax5WffiWnPdx3A3/nbTfguiQAAFB4iE25mQleFZ2Syjq9+3lJq+csFmlAfOSp8hOtIX2jNTQ5RoP7Rnk1ftgbTII7k8djqKTSpX9uK/aq5Dwwa7junJbJfTcIChQdAAAgSZqcEa9Uh/2sm5j2jQnXgmtGK7+sRvtKq7W3tFr7SqvlPNmgQ+W1OlReqw92lbZ6X6rDriFJ0RrcN1pDTytB8VHeb24a7JPgqlwNOnCsRgfKqk/9b40OHKvRwbIanWxwe/1x0uIiKDkIGhQdAAAgSbJZLZo/J0t3L9rUcl9Hs+brJo9cOUozRia3ep9hGDpWXad9pdXaf1r52VtarWNVdSp2ulTsdOmjvWWt3hcfFaYhSdFNj+YSlBStlFh7q+VU7d17UuJ06e5Fm0ydBNedV5ka3B4VVtTqwLEa5Zc1lZr9x5oKzVcn5p0uxGpR35hwr67oJMXYu5QN8EfcowMAAFrpzqsnztoG7TtWpX2nlZ99pdU6fPxku++JDg/R4KRoDU1quvfnT6sPtLqB/nRmToLryr8nwzBUVl3fVGSOVZ+6MtP0vwXltWr0tP9jWd+YcGUmRimzb/Sp/2365/Q+EbJYLJr62IdnvRrHxDwECoYRAACALuvp+2Fq6xt14FiN9pa2LkGHymvlPssP++25ZnyahiTHyB5ikz3UJnuoVfZQmyJCbQo/9c9Nr335vD3UpvAQq6xd+LrONuFMkn7/rXEamhzTtMzsWLXyy2q0/1Sp+epY79NFhNqUkRiljL5RGtxcavpGaVBilGI7uNepOZPU9tU49kBCoKDoAAAAv1Pf6NHB8lP3/xyt1qo9pdpUcKJHP2dYiFX2EKsiwmytClH4qTIU8ZWiFBZi1SvrClVd135hORuLReoXF9FyZWZw3yhlJDYVmpRYe5eKV7Ngv5cJwYGiAwAA/N7a/eW68U+fdnjcpSOTFRcZKlejR64G92mPU39uPPXP9U3/3ODu+R9/osJsGpYSo4zEKA1uWW4WrYEJkT06ipvpdAh0jJcGAAB+z5tJcCkOu569OadTP8y7PUZLGTp5WiGqO1WITtafVo6+Upy+OOJU3u5jHX6OX109WleO7+f9F9tNbFYLG7oCougAAAAf5s0kuPlzsjp9xcJmtSgqPERR4Z3/UWjt/nKvik5SLBPOADMxSB0AAPi0WdmpWnjTBKU4WheHFIfdlBvsm68ytVetLGq6L2ZyRnxvxgLwFVzRAQAAPm9WdqouzUrxiXtPeuoqE4DuxTACAACALmDCGWAOhhEAAAD0IF+6ygTgTBQdAACALmLCGeC7GEYAAAAAIOBQdAAAAAAEHIoOAAAAgIBD0QEAAAAQcCg6AAAAAAIORQcAAABAwKHoAAAAAAg4XSo6zzzzjDIyMmS325WTk6OPPvrorMevWrVKOTk5stvtyszM1LPPPtulsAAAAADgjU4XnVdffVU//vGP9dBDD2nz5s2aNm2aZs+erYKCgjaPz8/P1+WXX65p06Zp8+bN+tnPfqYf/vCHWrx48TmHBwAAAIC2WAzDMDrzhvPOO08TJkzQwoULW54bOXKkrrrqKi1YsOCM4x944AEtWbJEO3fubHlu7ty52rp1q9auXevV56ysrJTD4ZDT6VRsbGxn4gIAAAAIIN52g05d0amvr9fGjRs1c+bMVs/PnDlTa9asafM9a9euPeP4yy67TBs2bFBDQ0Ob76mrq1NlZWWrBwAAAAB4q1NFp6ysTG63W8nJya2eT05OVklJSZvvKSkpafP4xsZGlZWVtfmeBQsWyOFwtDzS09M7ExMAAABAkOvSMAKLxdLqz4ZhnPFcR8e39XyzBx98UE6ns+VRWFjYlZgAAAAAglRIZw5OTEyUzWY74+pNaWnpGVdtmqWkpLR5fEhIiBISEtp8T3h4uMLDw1v+3FyMWMIGAAAABLfmTtDRqIFOFZ2wsDDl5ORo+fLluvrqq1ueX758ua688so235Obm6ulS5e2eu7f//63Jk6cqNDQUK8+b1VVlSSxhA0AAACApKaO4HA42n2901PXXn31Vd1888169tlnlZubq+eee05/+tOf9MUXX2jgwIF68MEHVVRUpJdeeklS03jp7Oxs3XXXXbrzzju1du1azZ07V6+88oquvfZarz6nx+PRkSNHFBMTc9YlcpMmTdL69eu79Hp7r331+crKSqWnp6uwsNAnJsB19DX39sfszHu9OTYYz6nkW+e1s+/jvLbNl85pZ9/LOW1fd59XXzqn3hzn7bk72/O+dl596XuVv3+7TzB/r3bHOZV867wahqGqqiqlpaXJam3/TpxOXdGRpBtuuEHl5eV65JFHVFxcrOzsbL377rsaOHCgJKm4uLjVnjoZGRl699139R//8R96+umnlZaWpieffNLrkiNJVqtV/fv37/A4m8121n/xZ3u9vdfaez42Ntb0kyx1/DX39sfszHu9OTYYz6nkW+e1s+/jvLbNl85pZ9/LOW1fd59XXzqn3hzX2XN3to/nK+fVl75X+fu3+wTz92p3nlPJd87r2a7kNOt00ZGkH/zgB/rBD37Q5msvvvjiGc9ddNFF2rRpU1c+Vafcc889XX69vdc6+phm64l85/IxO/Neb44NxnMq+dZ57ez7OK9t86Vz2tn3ck7b190ZfemcenNcZ89dMJ7Tc/mY/P3bfYL5ezVQz6k3Or10LdixeWng4ZwGJs5r4OGcBibOa+DhnAYmfzyvXRovHczCw8M1f/78VlPh4N84p4GJ8xp4OKeBifMaeDingckfzytXdAAAAAAEHK7oAAAAAAg4FB0AAAAAAYeiAwAAACDgUHQAAAAABByKTg/ZvXu3xo0b1/KIiIjQ22+/bXYsdIP8/HxdfPHFysrK0ujRo1VTU2N2JJyjkJCQlu/VO+64w+w46Ea1tbUaOHCg7r//frOj4BxVVVVp0qRJGjdunEaPHq0//elPZkdCNygsLNT06dOVlZWlMWPG6PXXXzc7ErrB1VdfrT59+ui6664zNQdT13pBdXW1Bg0apEOHDikqKsrsODhHF110kf73f/9X06ZNU0VFhWJjYxUS0qW9d+EjEhMTVVZWZnYM9ICHHnpIe/fu1YABA/T444+bHQfnwO12q66uTpGRkaqtrVV2drbWr1+vhIQEs6PhHBQXF+vo0aMaN26cSktLNWHCBO3evZufl/xcXl6eqqur9de//lVvvPGGaTm4otMLlixZohkzZvBNGwC++OILhYaGatq0aZKk+Ph4Sg7go/bu3atdu3bp8ssvNzsKuoHNZlNkZKQkyeVyye12i9/V+r/U1FSNGzdOkpSUlKT4+HhVVFSYGwrn7OKLL1ZMTIzZMYK36KxevVpz5sxRWlqaLBZLm8vKnnnmGWVkZMhutysnJ0cfffRRlz7Xa6+9phtuuOEcE8MbPX1e9+7dq+joaH3jG9/QhAkT9Ktf/aob06MtvfG9WllZqZycHE2dOlWrVq3qpuQ4m944r/fff78WLFjQTYnRkd44pydOnNDYsWPVv39//eQnP1FiYmI3pUd7evPnpQ0bNsjj8Sg9Pf0cU+NsevOcmi1oi05NTY3Gjh2rp556qs3XX331Vf34xz/WQw89pM2bN2vatGmaPXu2CgoKWo7JyclRdnb2GY8jR460HFNZWalPPvmE3yj2kp4+rw0NDfroo4/09NNPa+3atVq+fLmWL1/eW19eUOqN79WDBw9q48aNevbZZ3XLLbeosrKyV762YNbT5/Wdd97RsGHDNGzYsN76koJeb3yvxsXFaevWrcrPz9fLL7+so0eP9srXFsx66+el8vJy3XLLLXruued6/GsKdr11Tn2CAUOS8dZbb7V6bvLkycbcuXNbPTdixAjjpz/9aac+9ksvvWR85zvfOdeI6IKeOK9r1qwxLrvsspY///rXvzZ+/etfn3NWeKcnv1ebzZo1y1i/fn1XI6ILeuK8/vSnPzX69+9vDBw40EhISDBiY2ONhx9+uLsiowO98b06d+5c47XXXutqRHRBT51Xl8tlTJs2zXjppZe6IyY6oSe/V/Py8oxrr732XCOek6C9onM29fX12rhxo2bOnNnq+ZkzZ2rNmjWd+lgsW/Md3XFeJ02apKNHj+r48ePyeDxavXq1Ro4c2RNx4YXuOKfHjx9XXV2dJOnw4cPasWOHMjMzuz0rvNcd53XBggUqLCzUwYMH9fjjj+vOO+/UL37xi56ICy90xzk9evRoy9XWyspKrV69WsOHD+/2rPBed5xXwzB022236ZJLLtHNN9/cEzHRCd35M7Av4C7qNpSVlcntdis5ObnV88nJySopKfH64zidTq1bt06LFy/u7ojogu44ryEhIfrVr36lCy+8UIZhaObMmfr617/eE3Hhhe44pzt37tRdd90lq9Uqi8Wi3//+94qPj++JuPBSd/0dDN/RHef08OHDuv3222UYhgzD0L333qsxY8b0RFx4qTvO6yeffKJXX31VY8aMablX5G9/+5tGjx7d3XHhhe76+/eyyy7Tpk2bVFNTo/79++utt97SpEmTujtuhyg6Z2GxWFr92TCMM547G4fDwfphH3Su53X27NmaPXt2d8fCOTiXczplyhR9/vnnPREL5+hcv1eb3Xbbbd2UCOfqXM5pTk6OtmzZ0gOpcK7O5bxOnTpVHo+nJ2LhHJzr37/vv/9+d0fqEpautSExMVE2m+2M5lpaWnpGw4X/4LwGHs5pYOK8Bh7OaWDivAaeQDunFJ02hIWFKScn54xpWsuXL9eUKVNMSoVzxXkNPJzTwMR5DTyc08DEeQ08gXZOg3bpWnV1tfbt29fy5/z8fG3ZskXx8fEaMGCA5s2bp5tvvlkTJ05Ubm6unnvuORUUFGju3LkmpkZHOK+Bh3MamDivgYdzGpg4r4EnqM6pSdPeTJeXl2dIOuNx6623thzz9NNPGwMHDjTCwsKMCRMmGKtWrTIvMLzCeQ08nNPAxHkNPJzTwMR5DTzBdE4thmEYPdylAAAAAKBXcY8OAAAAgIBD0QEAAAAQcCg6AAAAAAIORQcAAABAwKHoAAAAAAg4FB0AAAAAAYeiAwAAACDgUHQAAAAABByKDgAAAICAQ9EBAAAAEHAoOgAAAAACDkUHAAAAQMCh6AAAAAAIOP8f+xIxfwD+fuwAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x11d6f7848c0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T12:51:55.982266Z",
     "start_time": "2025-09-01T12:51:55.977811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_learning_rate = my_cb.learning_rates[np.argmin(my_cb.losses)] / 10\n",
    "best_learning_rate"
   ],
   "id": "fc62f007db63b816",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00026366508100181816"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T12:52:50.081201Z",
     "start_time": "2025-09-01T12:51:57.067340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=best_learning_rate)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=20, \n",
    "    validation_data=(X_test, y_test)\n",
    ")"
   ],
   "id": "76821d3204b65adb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 2ms/step - accuracy: 0.8899 - loss: 0.4152 - val_accuracy: 0.9316 - val_loss: 0.2368\n",
      "Epoch 2/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1ms/step - accuracy: 0.9414 - loss: 0.2090 - val_accuracy: 0.9483 - val_loss: 0.1758\n",
      "Epoch 3/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1ms/step - accuracy: 0.9556 - loss: 0.1573 - val_accuracy: 0.9579 - val_loss: 0.1405\n",
      "Epoch 4/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1ms/step - accuracy: 0.9632 - loss: 0.1257 - val_accuracy: 0.9637 - val_loss: 0.1198\n",
      "Epoch 5/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1ms/step - accuracy: 0.9697 - loss: 0.1037 - val_accuracy: 0.9682 - val_loss: 0.1044\n",
      "Epoch 6/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1ms/step - accuracy: 0.9756 - loss: 0.0873 - val_accuracy: 0.9703 - val_loss: 0.0977\n",
      "Epoch 7/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1ms/step - accuracy: 0.9788 - loss: 0.0753 - val_accuracy: 0.9743 - val_loss: 0.0868\n",
      "Epoch 8/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1ms/step - accuracy: 0.9814 - loss: 0.0657 - val_accuracy: 0.9755 - val_loss: 0.0837\n",
      "Epoch 9/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1ms/step - accuracy: 0.9840 - loss: 0.0582 - val_accuracy: 0.9750 - val_loss: 0.0820\n",
      "Epoch 10/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1ms/step - accuracy: 0.9857 - loss: 0.0514 - val_accuracy: 0.9771 - val_loss: 0.0790\n",
      "Epoch 11/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1ms/step - accuracy: 0.9877 - loss: 0.0454 - val_accuracy: 0.9778 - val_loss: 0.0769\n",
      "Epoch 12/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1ms/step - accuracy: 0.9893 - loss: 0.0404 - val_accuracy: 0.9778 - val_loss: 0.0740\n",
      "Epoch 13/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1ms/step - accuracy: 0.9904 - loss: 0.0361 - val_accuracy: 0.9790 - val_loss: 0.0727\n",
      "Epoch 14/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1ms/step - accuracy: 0.9917 - loss: 0.0322 - val_accuracy: 0.9791 - val_loss: 0.0734\n",
      "Epoch 15/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1ms/step - accuracy: 0.9930 - loss: 0.0289 - val_accuracy: 0.9784 - val_loss: 0.0736\n",
      "Epoch 16/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1ms/step - accuracy: 0.9937 - loss: 0.0259 - val_accuracy: 0.9806 - val_loss: 0.0709\n",
      "Epoch 17/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1ms/step - accuracy: 0.9947 - loss: 0.0228 - val_accuracy: 0.9777 - val_loss: 0.0759\n",
      "Epoch 18/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1ms/step - accuracy: 0.9956 - loss: 0.0204 - val_accuracy: 0.9783 - val_loss: 0.0730\n",
      "Epoch 19/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1ms/step - accuracy: 0.9961 - loss: 0.0181 - val_accuracy: 0.9794 - val_loss: 0.0714\n",
      "Epoch 20/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1ms/step - accuracy: 0.9968 - loss: 0.0163 - val_accuracy: 0.9791 - val_loss: 0.0727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x11d76fa2210>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T12:53:13.104114Z",
     "start_time": "2025-09-01T12:53:12.721414Z"
    }
   },
   "cell_type": "code",
   "source": "model.evaluate(X_test, y_test)",
   "id": "3b5a37a56bfcda86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9791 - loss: 0.0727  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07266919314861298, 0.9790999889373779]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T12:53:15.426963Z",
     "start_time": "2025-09-01T12:53:15.018151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras_tuner as kt\n",
    "def build_model(hp):\n",
    "    n_hidden = hp.Int('num_hidden', min_value=2, max_value=12, step=32)\n",
    "    n_neurons = hp.Int('num_neurons', min_value=32, max_value=512, step=32)\n",
    "    learning_rates = hp.Float('learning_rate', min_value=1e-7, max_value=1e-2, sampling='log')\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\"]) \n",
    "    activation = hp.Choice(\"activation\", values=[\"relu\", \"sigmoid\", \"tanh\", \"softplus\"])\n",
    "    \n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rates)\n",
    "    elif optimizer == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rates)\n",
    "        \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "    for _ in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons, activation=activation))\n",
    "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "id": "b1b1c74b07b39b7b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "random_search = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=5,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"mnist\",\n",
    "    overwrite=True\n",
    ")\n",
    "random_search.search(X_train, y_train, validation_data=(X_test, y_test), epochs=10)"
   ],
   "id": "b6ff6f40144d39be",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 23s]\n",
      "val_accuracy: 0.9688000082969666\n",
      "\n",
      "Best val_accuracy So Far: 0.9779000282287598\n",
      "Total elapsed time: 00h 02m 22s\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T12:56:03.313218Z",
     "start_time": "2025-09-01T12:56:03.307703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "from time import strftime\n",
    "def get_run_logdir(root_logdir=\"my_logs\"):\n",
    "    return Path(root_logdir) / strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ],
   "id": "359ad02d528db3a9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('my_logs/run_2025_09_01_20_56_03')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T12:56:33.062444Z",
     "start_time": "2025-09-01T12:56:05.608148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir,\n",
    "                                                profile_batch=(100, 200))\n",
    "best_models = random_search.get_best_models(num_models=3)[0]\n",
    "best_models.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), callbacks=[tf.keras.callbacks.EarlyStopping(patience=5), tensorboard_cb])\n",
    "best_models.evaluate(X_test, y_test)"
   ],
   "id": "ae59572f3f1cf968",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\31752\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 2ms/step - accuracy: 0.9913 - loss: 0.0300 - val_accuracy: 0.9771 - val_loss: 0.0725\n",
      "Epoch 2/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 2ms/step - accuracy: 0.9935 - loss: 0.0233 - val_accuracy: 0.9781 - val_loss: 0.0698\n",
      "Epoch 3/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 2ms/step - accuracy: 0.9950 - loss: 0.0187 - val_accuracy: 0.9763 - val_loss: 0.0744\n",
      "Epoch 4/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 2ms/step - accuracy: 0.9966 - loss: 0.0141 - val_accuracy: 0.9783 - val_loss: 0.0726\n",
      "Epoch 5/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 2ms/step - accuracy: 0.9970 - loss: 0.0125 - val_accuracy: 0.9779 - val_loss: 0.0758\n",
      "Epoch 6/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 2ms/step - accuracy: 0.9978 - loss: 0.0098 - val_accuracy: 0.9780 - val_loss: 0.0742\n",
      "Epoch 7/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 2ms/step - accuracy: 0.9984 - loss: 0.0074 - val_accuracy: 0.9788 - val_loss: 0.0743\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9788 - loss: 0.0743  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07433544099330902, 0.9787999987602234]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T13:00:39.072447Z",
     "start_time": "2025-09-01T13:00:38.729303Z"
    }
   },
   "cell_type": "code",
   "source": "!kill 46064",
   "id": "2597da8b97b2ee0e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kill: 46064: No such process\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T13:01:32.309599Z",
     "start_time": "2025-09-01T13:01:26.456162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6007"
   ],
   "id": "450d4c519d2549ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3305504f97cb731c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3305504f97cb731c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T12:47:42.308796Z",
     "start_time": "2025-09-01T12:47:42.011162Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3ef0739a1437ca22",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kill: 46064: No such process\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 第二部分",
   "id": "aa17e7e1e0f2258c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "第二部分要求构建一个基本的softmax回归算法，以及一个简单的两层神经网络。将使用原生Python（使用numpy库），不借助keras实现这些算法\n",
    "\n",
    "在此过程中，将提供一些关于如何实现这些不同函数的指导，但总体而言，细节需要自己实现。 应该尽量使用 numpy 中的线性代数调用：for/while循环通常会使代码运行速度比预期慢得多。\n",
    "\n",
    "**请仔细阅读作业说明!!!**"
   ],
   "id": "6c3f1fe62132569f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "去命令行（cmd/Anaconda Powershell Prompt /其他终端）运行如下指令（激活开发环境一定要最先执行），安装这部分作业依赖的python库：\n",
    "- 激活开发环境：conda activate homl3\n",
    "- 安装numdifftools：conda install numdifftools\n",
    "- 安装pytest：conda install pytest\n"
   ],
   "id": "bbec9387c82d28a6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 第一题：简单的加法函数，以及使用pytest测试代码",
   "id": "4c898f53cabb194f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "为了说明这部分作业的代码+数据，以及pytest使用，将使用一个实现 add函数 的简单示例。\n",
    "\n",
    "```\n",
    "data/\n",
    "    train-images-idx3-ubyte.gz\n",
    "    train-labels-idx1-ubyte.gz\n",
    "    t10k-images-idx3-ubyte.gz\n",
    "    t10k-labels-idx1-ubyte.gz\n",
    "src/\n",
    "    simple_ml.py\n",
    "tests/\n",
    "    test_simple_ml.py\n",
    "```\n",
    "\n",
    "data/ 目录包含这部分作业所需的数据（MNIST 数据集的副本）；src/ 目录包含实现功能所需的源代码；tests/ 目录包含用于测试实现代码是否正确的代码\n",
    "\n",
    "第一题要求实现 src/目录里 simple_ml.py内的 add函数（这个简单的函数实际上并没有用到，它只是一个帮助熟悉作业结构的示例）。查看 src/simple_ml.py 文件，将找到 add() 函数的定义"
   ],
   "id": "e9c91dfa3c0912a8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```python\n",
    "def add(x, y):\n",
    "    \"\"\"一个简单的add函数，以便熟悉自动测试（pytest）\n",
    "\n",
    "    Args:\n",
    "        x (Python数字 或者 numpy array)\n",
    "        y (Python数字 或者 numpy array)\n",
    "\n",
    "    Return:\n",
    "        x+y的和\n",
    "    \"\"\"\n",
    "    ### 你的代码开始\n",
    "    pass\n",
    "    ### 你的代码结束\n",
    "```\n",
    "\n",
    "函数内的文档字符串（docstring）定义了函数应该产生的预期输入和输出（需要养成仔细阅读文档的习惯，很多错误来源就是没有阅读规范）。实现这个函数。你只需将 pass 语句替换为正确的代码即可，即：\n",
    "\n",
    "```python\n",
    "def add(x, y):\n",
    "    \"\"\"一个简单的add函数，以便熟悉自动测试（pytest）\n",
    "\n",
    "    Args:\n",
    "        x (Python数字 或者 numpy array)\n",
    "        y (Python数字 或者 numpy array)\n",
    "\n",
    "    Return:\n",
    "        x+y的和\n",
    "    \"\"\"\n",
    "    ### 你的代码开始\n",
    "    return x + y\n",
    "    ### 你的代码结束\n",
    "```\n",
    "\n",
    "现在可以去src/simple_nn.py里，把add函数里的pass 换成 return x + y"
   ],
   "id": "b968917c2ee80ca7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 测试代码",
   "id": "919bb56f32b06378"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "现在需要测试一下你的代码是否能正确运行，正确运行才说明实现没问题。\n",
    "\n",
    "在这部分作业中，将使用pytest对代码进行单元测试。在 src/simple_ml.py 文件中 写完 add函数的实现后，去命令行里确保已经激活了homl3环境（conda activate homl3）， 确保homl3环境里安装过了numdifftools和pytest，确定命令行里显示的文件路径在 作业8的目录（这个目录同时有data/, src/和tests/文件夹），然后执行以下命令：\n",
    "\n",
    "python -m pytest -k \"add\"\n",
    "\n",
    "如果一切正常，你会看到类似这样的图片：\n",
    "![测试add通过](../../images/homework/neural_network/p1.png)\n",
    "\n",
    "想看测试如何进行的，可以去查看tests/test_simple_ml.py文件，python -m pytest -k \"add\"指令刚刚运行的是 文件里的test_add() 函数\n",
    "\n",
    "如果错误地实现了某些内容（例如，将上面的 x + y 更改为 x - y），那么测试将会失败，并且 pytest 将会指示相应的测试失败。\n",
    "\n",
    "比如把x+y，换成x-y后，执行python -m pytest -k \"add\"：\n",
    "![测试add不通过](../../images/homework/neural_network/p2.png)"
   ],
   "id": "8cd29340f4d80aac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "b如图所见，将收到一个错误，指示断言失败，然后就可以使用它来返回并调整实现代码。应该能够熟练地阅读和跟踪测试文件，以便更好地理解正确的实现应该如何工作\n",
    "\n",
    "学习正确开发和使用单元测试对于现代软件开发至关重要，希望这次作业帮助了解单元测试在软件开发中的典型用法。\n",
    "\n",
    "当然，这次作业不一定需要编写自己的测试去确保自己实现正确，但应该熟悉如何阅读提供的测试文件，以便了解要实现的函数应该如何运行。但是，也绝对鼓励为自己的实现编写额外的测试。\n",
    "\n",
    "如果习惯通过打印语句调试代码，请注意，pytest 默认会捕获任何输出（隐藏掉测试代码执行的print）。可以通过将 -s 传递给 pytest 来禁用此行为并让测试在所有情况下显示所有输出。"
   ],
   "id": "33304ba8ce802fd2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "b### 第二题：用gzip和struct处理压缩文件和二进制数据，加载MNIST数据",
   "id": "ebec5034752b27"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "现在已经熟悉了测试工具pytest，接下来在 src/simple_nn.py 中需要实现的函数上尝试一下：parse_mnist_data() 函数。\n",
    "\n",
    "这个函数也有文档字符串（docstring），请仔细阅读它们。\n",
    "\n",
    "然后，请访问 https://web.archive.org/web/20220509025752/http://yann.lecun.com/exdb/mnist/ 了解 MNIST 数据的二进制格式。然后编写函数读取此类文件，并根据文档字符串中的规范返回 numpy 数组）。建议使用 Python 中的 struct 模块（以及 gzip 模块，当然还有 numpy 本身）来实现此函数。\n",
    "\n",
    "当然可以利用AI搜索这个部分的代码实现，但了解了MNIST数据的二进制格式和gzip，struct的简单使用后，能理解AI产出的代码为什么正确\n",
    "\n",
    "实现函数后，去命令行运行本地单元测试， 同样确保命令行激活了homl3环境，确保路径在作业8目录下（有data/,src/和tests/ 文件夹）， 后面的题不再强调\n",
    "\n",
    "python -m pytest -k \"parse_mnist\""
   ],
   "id": "f22b95e3905b669b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 第三题：Softmax损失",
   "id": "1323562d0cba4cfa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在 `src/simple_ml.py` 文件的 `softmax_loss()` 函数中实现 softmax（也称为交叉熵）损失。对于一个可以取值 $ y \\in \\{1, \\ldots, k\\} $ 的多类输出，softmax 损失接收一个对数几率向量 $ z \\in \\mathbb{R}^k $ 和真实类别 $ y \\in \\{1, \\ldots, k\\} $ 作为输入，并返回由以下公式定义的损失：\n",
    "\n",
    "$\\ell_{\\text{softmax}}(z, y) = \\log (\\sum_{i=1}^{k} \\exp z_i) - z_y$\n",
    "\n",
    "对数几率向量z，可以看成被softmax激活之前的值，对公式有疑惑，或者对z的意义有疑惑的，可以参考softmax回归的笔记，并自己推导一下损失公式是否正确\n",
    "\n",
    "请注意，如其文档字符串（docstring）所述，`softmax_loss()` 函数接收一个二维的对数几率数组（即，一批不同样本的 $ k $ 维对数几率）加上一个对应的一维真实标签数组，并应返回整批样本的平均 softmax 损失。请注意，为了正确实现此功能，你不应使用任何循环，而是完全使用 numpy 的向量化操作进行计算（为此设定预期，实现代码可以少到一行代码）。"
   ],
   "id": "3cdb52032ac61c62"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "实现完成后，可以去命令行进行单元测试：python -m pytest -k \"softmax_loss\"",
   "id": "413eec903944c28e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 第四题：softmax回归小批量梯度下降",
   "id": "a3f4e9cefaaa8dc4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在这个问题中，你将实现（线性）softmax 回归的小批量梯度下降）。考虑一个假设函数，该函数通过以下公式将 $ n $ 维输入转换为 $ k $ 维对数几率：\n",
    "\n",
    "$h(x) = \\Theta^T x$\n",
    "\n",
    "其中 $ x \\in \\mathbb{R}^n $ 是输入，$\\Theta \\in \\mathbb{R}^{n \\times k}$ 是模型参数。给定数据集 $\\{(x^{(i)} \\in \\mathbb{R}^n, y^{(i)} \\in \\{1, \\ldots, k\\})\\}$，其中 $ i = 1, \\ldots, m $，softmax 回归相关的优化问题因此由下式给出：\n",
    "\n",
    "$\\text{minimize} \\frac{1}{m} \\sum_{i=1}^{m} \\ell_{\\text{softmax}} (\\Theta^T x^{(i)}, y^{(i)})$\n",
    "\n",
    "线性 softmax 目标的梯度由下式给出，有疑惑的可以结合softmax回归的笔记验证\n",
    "\n",
    "$\\nabla_\\Theta \\ell_{\\text{softmax}} (\\Theta^T x, y) = x(z - e_y)^T$\n",
    "\n",
    "其中\n",
    "\n",
    "$z = \\frac{\\exp(\\Theta^T x)}{1^T \\exp(\\Theta^T x)} = \\text{normalize}(\\exp(\\Theta^T x))$\n",
    "\n",
    "（即 $ z $ 只是归一化的 softmax 概率），并且 $ e_y $ 表示 y 分类的独热编码，即一个所有元素为零，只有第 $ y $ 个位置为 1 的向量。\n",
    "\n",
    "也可以用更紧凑的符号来表示，方便代码实现，即，如果让 $ X \\in \\mathbb{R}^{m \\times n} $ 表示某个 $ m $ 个输入的特征矩阵（整个数据集或一个小批量），$ y \\in \\{1, \\ldots, k\\}^m $ 是对应的标签向量，并且 $ \\ell_{\\text{softmax}} $ 表示平均 softmax 损失，那么\n",
    "\n",
    "$\\nabla_\\Theta \\ell_{\\text{softmax}}(X \\Theta, y) = \\frac{1}{m} X^T (Z - I_y)$\n",
    "\n",
    "其中\n",
    "\n",
    "$Z = \\text{normalize}(\\exp(X \\Theta)) \\quad (\\text{归一化按行应用})$\n",
    "\n",
    "表示对数几率矩阵，而 $ I_y \\in \\mathbb{R}^{m \\times k} $ 表示 $ y $ 中标签的 逐个转成 独热编码，按行连接\n",
    "\n",
    "使用这些梯度，实现 `softmax_regression_epoch()` 函数，该函数使用指定的学习率/步长 $ \\eta $ 和小批量大小 `batch_size` 运行单个轮次（对数据集的一次遍历）。如其文档字符串所述，你的函数应该就地修改 Theta 数组。实现后，请去命令行运行测试。\n",
    "\n",
    "python -m pytest -k \"softmax_regression_epoch\""
   ],
   "id": "67f005120ef5a202"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 用softmax回归训练MNIST",
   "id": "f0e6a75ce062199d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "虽然这不包含在测试中，但既然你已经编写了这段代码，你也可以尝试使用 SGD 训练一个完整的 MNIST 线性分类器。为此，你可以使用 src/simple_ml.py 文件中的 train_softmax() 函数（已经编写好了这个函数，所以无需自行编写，但可以查看一下它的功能）。\n",
    "\n",
    "可以使用以下代码了解它的工作原理。作为参考，如下所示，我的实现在 notebook 上运行时间约为 2 秒，测试集错误率为 7.97%。"
   ],
   "id": "fc5478e35ebb74bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T02:44:49.214986Z",
     "start_time": "2025-09-02T02:44:47.192082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.append(\"src/\")\n",
    "from simple_nn import train_softmax, parse_mnist\n",
    "\n",
    "X_tr, y_tr = parse_mnist(\"data/train-images-idx3-ubyte.gz\",\n",
    "                         \"data/train-labels-idx1-ubyte.gz\")\n",
    "X_te, y_te = parse_mnist(\"data/t10k-images-idx3-ubyte.gz\",\n",
    "                         \"data/t10k-labels-idx1-ubyte.gz\")\n",
    "\n",
    "train_softmax(X_tr, y_tr, X_te, y_te, epochs=10, lr=0.2, batch=100)"
   ],
   "id": "2a7bf41f4f1f5211",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch | Train Loss | Train Err | Test Loss | Test Err |\n",
      "|     0 |    0.35134 |   0.10182 |   0.33588 |  0.09400 |\n",
      "|     1 |    0.32142 |   0.09268 |   0.31086 |  0.08730 |\n",
      "|     2 |    0.30802 |   0.08795 |   0.30097 |  0.08550 |\n",
      "|     3 |    0.29987 |   0.08532 |   0.29558 |  0.08370 |\n",
      "|     4 |    0.29415 |   0.08323 |   0.29215 |  0.08230 |\n",
      "|     5 |    0.28981 |   0.08182 |   0.28973 |  0.08090 |\n",
      "|     6 |    0.28633 |   0.08085 |   0.28793 |  0.08080 |\n",
      "|     7 |    0.28345 |   0.07997 |   0.28651 |  0.08040 |\n",
      "|     8 |    0.28100 |   0.07923 |   0.28537 |  0.08010 |\n",
      "|     9 |    0.27887 |   0.07847 |   0.28442 |  0.07970 |\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 在1个隐藏层的神经网络上进行小批量梯度下降",
   "id": "6e72acd86987b24e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "现在已经为线性分类器编写了SGD，现在考虑一个简单的两层神经网络的情况。具体来说，对于输入 $ x \\in \\mathbb{R}^n $，考虑一个形式如下的两层神经网络（无偏置项）：\n",
    "\n",
    "$ z = W_2^T ReLU(W_1^T x) $\n",
    "\n",
    "其中 $ W_1 \\in \\mathbb{R}^{n \\times d} $ 和 $ W_2 \\in \\mathbb{R}^{d \\times k} $ 表示网络的权重（具有 $ d $ 维隐藏单元），而 $ z \\in \\mathbb{R}^k $ 表示网络输出的对数几率。我们再次使用 softmax/交叉熵损失，这意味着我们要解决以下优化问题：\n",
    "\n",
    "$\\text{minimize } \\frac{1}{W_1, W_2} \\sum_{i=1}^m \\ell_{\\text{softmax}}(W_2^T ReLU(W_1^T x^{(i)}), y^{(i)})$\n",
    "\n",
    "或者，使用矩阵 $ X \\in \\mathbb{R}^{m \\times n} $ 来描述批量形式，这也可以写成：\n",
    "\n",
    "$\\text{minimize } \\ell_{\\text{softmax}}(ReLU(XW_1)W_2, y)$\n",
    "\n",
    "使用链式法则，可以推导出该网络的反向传播更新（为了便于实现，这里提供最终形式）。具体来说，令：\n",
    "\n",
    "$Z_1 \\in \\mathbb{R}^{m \\times d} = ReLU(XW_1)$\n",
    "\n",
    "$G_2 \\in \\mathbb{R}^{m \\times k} = \\text{normalize}(\\exp(Z_1 W_2)) - I_y$\n",
    "\n",
    "$G_1 \\in \\mathbb{R}^{m \\times d} = 1\\{Z_1 > 0\\} \\circ (G_2 W_2^T)$\n",
    "\n",
    "其中 $ 1\\{Z_1 > 0\\} $ 是一个二进制矩阵，其条目根据 $ Z_1 $ 中的每个项是否严格为正而等于零或一，而 $\\circ$ 表示逐元素乘法。那么目标的梯度由下式给出：\n",
    "\n",
    "$\\nabla_{W_1} \\ell_{\\text{softmax}}(ReLU(XW_1)W_2, y) = \\frac{1}{m} X^T G_1$\n",
    "\n",
    "$\\nabla_{W_2} \\ell_{\\text{softmax}}(ReLU(XW_1)W_2, y) = \\frac{1}{m} Z_1^T G_2$\n",
    "\n",
    "**注意：** 如果这些精确方程的细节对你来说有点神秘，不必太担心。这些只是两层ReLU网络的标准反向传播方程：$ Z_1 $ 项只是计算\"前向\"传播，而 $ G_2 $ 和 $ G_1 $ 项表示反向传播。但是更新的精确形式可能会因你使用的神经网络符号、制定损失函数的具体方式、是否之前以矩阵形式推导过这些等因素而有所不同。（毕竟，在某种程度上，深度学习系统（比如tensorflow）的整个重点是我们不需要费心进行这些手动计算）。\n"
   ],
   "id": "f6a35e81834a15a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "使用这些梯度，现在在 src/simple_ml.py 文件中编写 nn_epoch() 函数。与上一个问题一样，你的解决方案应该修改 W1 和 W2 数组。实现该函数后，运行以下测试。请务必使用上述表达式所示的矩阵运算来实现该函数：这比尝试使用循环更快、更高效（并且所需的代码也更少）。\n",
    "\n",
    "实现完成后，去命令运行单元测试：python -m pytest -k \"nn_epoch\""
   ],
   "id": "53c19e9d5f2d9c32"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 训练神经网络",
   "id": "ff593cbba822cafb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T03:11:14.608727Z",
     "start_time": "2025-09-02T03:10:47.588424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "import importlib\n",
    "import simple_nn\n",
    "importlib.reload(simple_nn) # 重新载入simple_nn， 防止刚才的训练代码产生了缓存，影响了simple_nn\n",
    "\n",
    "sys.path.append(\"src/\")\n",
    "from simple_nn import train_nn, parse_mnist\n",
    "\n",
    "X_tr, y_tr = parse_mnist(\"data/train-images-idx3-ubyte.gz\",\n",
    "                         \"data/train-labels-idx1-ubyte.gz\")\n",
    "X_te, y_te = parse_mnist(\"data/t10k-images-idx3-ubyte.gz\",\n",
    "                         \"data/t10k-labels-idx1-ubyte.gz\")\n",
    "train_nn(X_tr, y_tr, X_te, y_te, hidden_dim=400, epochs=20, lr=0.2)"
   ],
   "id": "3f41ff4fe2309f37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch | Train Loss | Train Err | Test Loss | Test Err |\n",
      "|     0 |    0.15324 |   0.04697 |   0.16305 |  0.04920 |\n",
      "|     1 |    0.09854 |   0.02923 |   0.11604 |  0.03660 |\n",
      "|     2 |    0.07428 |   0.02180 |   0.09767 |  0.03200 |\n",
      "|     3 |    0.05936 |   0.01732 |   0.08745 |  0.02850 |\n",
      "|     4 |    0.04856 |   0.01362 |   0.08133 |  0.02570 |\n",
      "|     5 |    0.04032 |   0.01088 |   0.07661 |  0.02400 |\n",
      "|     6 |    0.03473 |   0.00887 |   0.07416 |  0.02310 |\n",
      "|     7 |    0.03030 |   0.00760 |   0.07234 |  0.02320 |\n",
      "|     8 |    0.02669 |   0.00653 |   0.07117 |  0.02240 |\n",
      "|     9 |    0.02371 |   0.00552 |   0.06998 |  0.02140 |\n",
      "|    10 |    0.02124 |   0.00488 |   0.06929 |  0.02140 |\n",
      "|    11 |    0.01894 |   0.00403 |   0.06812 |  0.02140 |\n",
      "|    12 |    0.01705 |   0.00313 |   0.06756 |  0.02110 |\n",
      "|    13 |    0.01556 |   0.00270 |   0.06719 |  0.02140 |\n",
      "|    14 |    0.01423 |   0.00240 |   0.06685 |  0.02090 |\n",
      "|    15 |    0.01298 |   0.00215 |   0.06645 |  0.02100 |\n",
      "|    16 |    0.01195 |   0.00190 |   0.06613 |  0.02030 |\n",
      "|    17 |    0.01094 |   0.00155 |   0.06580 |  0.02020 |\n",
      "|    18 |    0.01001 |   0.00112 |   0.06536 |  0.01960 |\n",
      "|    19 |    0.00925 |   0.00095 |   0.06532 |  0.01890 |\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "作为参考，我的实现花了30多秒训练，最终在mnist的测试集达到了1.93%的错误率，只用了大概20多行代码",
   "id": "24c53df020c227d7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
