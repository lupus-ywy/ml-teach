{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 简答题\n",
    "1. 如果训练集有100万个实例，训练决策树（无约束）大致的深度是多少？\n",
    "\n",
    "20\n",
    "\n",
    "2. 通常来说，子节点的基尼杂质是高于还是低于其父节点？是通常更高/更低？还是永远更高/更低？\n",
    "\n",
    "一个节点的基尼不纯度通常比其父节点低\n",
    "\n",
    "3. 如果决策树过拟合训练集，减少max_depth是否为一个好主意？\n",
    "\n",
    "是一个好主意，降低max_depth可以降低模型复杂度\n",
    "\n",
    "4. 如果决策树对训练集欠拟合，尝试缩放输入特征是否为一个好主意？\n",
    "\n",
    "不是好主意，缩放特征不会影响决策树的分割结果\n",
    "\n",
    "5. 如果在给定的训练集上训练决策树需要一个小时，那么如果将特征数量变为两倍，训练大约需要多少时间？\n",
    "\n",
    "2小时\n",
    "\n",
    "6. 如果在包含100万个实例的训练集上训练决策树需要一个小时，那么在包含1000万个实例的训练集上训练决策树，大概需要多长时间？提示：考虑CART算法的计算复杂度。\n",
    "\n",
    "10-15小时"
   ],
   "id": "c8b56739308b5b88"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 编程题",
   "id": "d57bc0d1695fa8ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. 为 新月形 数据集训练并微调一棵决策树。\n",
    "\n",
    "a. 使用make_moons(n_samples=10000，noise=0.4)生成一个 新月形 数据集。\n",
    "\n",
    "b. 使用train_test_split()拆分训练集和测试集。\n",
    "\n",
    "c. 使用交叉验证的网格搜索（在GridSearchCV类的帮助下）为Decision-TreeClassifier找到适合的超参数值。提示：尝试max_leaf_nodes的多种值。\n",
    "\n",
    "d. 使用超参数对整个训练集进行训练，并测量模型在测试集上的性能。你应该得到约85%～87%的准确率。"
   ],
   "id": "df859f669d173482"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T13:11:57.930467Z",
     "start_time": "2025-08-17T13:11:44.518844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X, y = make_moons(n_samples=10000, noise=0.4)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'max_leaf_nodes': [None, 10, 20, 30, 50, 100, 200],\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "grid_search = GridSearchCV(dt, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "grid_search.best_params_, grid_search.best_score_, grid_search.best_estimator_"
   ],
   "id": "c350128b89757bbb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': None,\n",
       "  'max_leaf_nodes': 10,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_samples_split': 2},\n",
       " 0.854875,\n",
       " DecisionTreeClassifier(max_leaf_nodes=10, random_state=42))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T13:12:00.060423Z",
     "start_time": "2025-08-17T13:12:00.046022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "best_dt = grid_search.best_estimator_\n",
    "best_dt.fit(X_train, y_train)\n",
    "y_pred = best_dt.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ],
   "id": "7af4fcbef23a5930",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.851"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "2. 按照以下步骤种植森林。\n",
    "\n",
    "a.继续之前的练习，生产1000个训练集子集，每个子集包含随机挑选的100个实例。提示：使用Scikit-Learn的ShuffleSplit类来实现。\n",
    "\n",
    "b.使用前面得到的最佳超参数值，在每个子集上训练一棵决策树。在测试集上评估这1000棵决策树。因为训练集更小，所以这些决策树的表现可能比第一棵决策树要差一些，只能达到约80%的精度。\n",
    "\n",
    "c.见证奇迹的时刻到了。用每个测试集实例，生成1000棵决策树的预测，然后仅保留次数最频繁的预测［可以使用SciPy的mode()函数］。这样你在测试集上可获得大多数投票的预测结果。\n",
    "\n",
    "d.评估测试集上的这些预测，你得到的准确率应该比第一个模型更高（高出0.5%～1.5%）。恭喜，你已经训练出了一个随机森林分类器！"
   ],
   "id": "ed6c04b5518d9498"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T13:12:04.383192Z",
     "start_time": "2025-08-17T13:12:03.562037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.stats import mode\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "shuffle_split = ShuffleSplit(n_splits=1000, train_size=100, random_state=42)\n",
    "X_train_subsets = []\n",
    "y_train_subsets = []\n",
    "for train_index, test_index in shuffle_split.split(X_train):\n",
    "    X_train_subsets.append(X_train[train_index])\n",
    "    y_train_subsets.append(y_train[train_index])\n",
    "y_pred = []\n",
    "for i in range(1000):\n",
    "    best_dt.fit(X_train_subsets[i], y_train_subsets[i])\n",
    "    y_pred.append(best_dt.predict(X_test))\n",
    "result = mode(y_pred, axis=0)\n",
    "accuracy = accuracy_score(y_test, result[0])\n",
    "accuracy"
   ],
   "id": "c73f731a299a3a99",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8575"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "\n",
   "id": "2db0ac58f6f5a8b4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
